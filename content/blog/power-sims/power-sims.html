---
title: "Writing your own Power Simulations in R"
author: "Katherine Hoffman"
date: 2019-12-31T21:13:14-05:00
categories: ["R"]
tags: ["R"]
output: 
  blogdown::html_page:
    toc: true
    smart: false
    df_print: "paged"
---

<link href="/rmarkdown-libs/pagedtable/css/pagedtable.css" rel="stylesheet" />
<script src="/rmarkdown-libs/pagedtable/js/pagedtable.js"></script>

<div id="TOC">
<ul>
<li><a href="#tldr">TLDR</a></li>
<li><a href="#a-review-of-statistical-power">A review of statistical power</a></li>
<li><a href="#simulating-one-analysis">Simulating one analysis</a></li>
<li><a href="#simulating-power-for-one-analysis">Simulating power for one analysis</a></li>
<li><a href="#simulating-the-power-curve-over-sample-size">Simulating the power curve over sample size</a></li>
<li><a href="#simulating-power-curves-for-many-sample-and-effect-sizes">Simulating power curves for many sample and effect sizes</a></li>
</ul>
</div>

<hr />
<div id="tldr" class="section level1">
<h1>TLDR</h1>
<ul>
<li><p>Statistical power is the proportion of times we reject the null hypothesis when the null hypothesis is false</p></li>
<li><p>We can estimate power for any hypothesis test by repeating our analysis many times and calculating the proportion of times we reject our null hypothesis</p></li>
<li><p>Skip to the <a href="#full-code-without-explanations">end of the post</a> for <code>R</code> simulation code without text explanations</p></li>
</ul>
<hr />
</div>
<div id="a-review-of-statistical-power" class="section level1">
<h1>A review of statistical power</h1>
<p>introduction</p>
<hr />
</div>
<div id="simulating-one-analysis" class="section level1">
<h1>Simulating one analysis</h1>
<p>We’ll look at simulation examples using one of the most straightforward analyses: simple linear regression. Although you would never need to do a power calculation simulation for a simple linear regression because there is a formula for it, the concepts and code can easily be applied to a more complicated analysis in which formulas do not exist.</p>
<p>We start by loading the packages needed for this analysis, and setting a seed for reproducible results:</p>
<pre class="r"><code>library(dplyr)
library(ggplot2)
library(broom)
library(kableExtra)
library(purrr)
library(future.apply)
library(furrr)</code></pre>
<pre class="r"><code>set.seed(7)</code></pre>
<p>We will generate a data set with sample size <code>n</code> of <code>100</code> and a population mean <code>mu</code> of some measure equal to <code>50</code> with standard deviation of <code>10</code>. We’ll randomly assign a treatment we’ll call <code>A</code>, of which the true effect on these measures in our population is a difference, or <code>delta</code> of <code>5</code>.</p>
<pre class="r"><code>n &lt;- 100
mu &lt;- 50
sd &lt;- 10
delta &lt;- 5
A &lt;- rep(c(0,1), each=n/2)</code></pre>
<p>With these parameters set, it becomes easy to generate our outcome <code>Y</code> under the assumption that our measure of interest is a <code>r</code>andom variable <code>norm</code>ally distributed with mean <code>mu</code>, standard deviation <code>sd</code>. Our outcome changes a <code>delta</code> amount due to our treatment <code>A</code>.</p>
<pre class="r"><code>Y &lt;- rnorm(n, mean = mu, sd = sd) + A*delta</code></pre>
<p>We put our data of interest (the treatment assigned, <code>A</code>, and resultant outcome, <code>Y</code>) into a tibble/data frame.</p>
<pre class="r"><code>dat &lt;- tibble(A, Y)</code></pre>
<p>Then we can plot the distributions of the two groups as a sanity check.</p>
<pre class="r"><code>dat %&gt;%
  group_by(A) %&gt;% mutate(mean_Y = mean(Y)) %&gt;% ungroup() %&gt;%
  mutate(A = factor(A, levels=0:1, labels=c(&quot;control&quot;,&quot;treatment&quot;))) %&gt;%
  ggplot(aes(Y, col=A)) +
  geom_density(alpha=.5) +
  geom_vline(aes(xintercept=mean_Y, col=A),
            linetype=&quot;dashed&quot;) +
  ggtitle(&quot;Distribution of Y under Treatment and Control&quot;) +
  theme_classic() +
  scale_y_continuous(expand=c(0,0)) </code></pre>
<p><img src="/blog/power-sims/power-sims_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>We see the distributions of both the treatment and control groups look normally distributed, and the treated group has a higher mean.</p>
<p>We can fit a linear model for our outcome given treatment and see the estimate of our treatment effect from this data set is 3. At an alpha level of 0.05, we would fail to reject our null hypothesis because the p-value is 0.121.</p>
<pre class="r"><code>fit &lt;- lm(Y ~ A, data = dat)
fit %&gt;% tidy %&gt;% kable(digits=3)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
52.387
</td>
<td style="text-align:right;">
1.355
</td>
<td style="text-align:right;">
38.652
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
3.000
</td>
<td style="text-align:right;">
1.917
</td>
<td style="text-align:right;">
1.565
</td>
<td style="text-align:right;">
0.121
</td>
</tr>
</tbody>
</table>
<p>However, if we were to resample our data again, the next time we may randomly draw samples that, after fitting our linear model, <em>do</em> give us enough evidence to reject the null hypothesis:</p>
<pre class="r"><code>Y &lt;- rnorm(n, mean = mu, sd = sd) + A*delta
fit &lt;- lm(Y ~ A)
fit %&gt;% tidy %&gt;% kable(digits=3)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
51.852
</td>
<td style="text-align:right;">
1.347
</td>
<td style="text-align:right;">
38.505
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
3.904
</td>
<td style="text-align:right;">
1.904
</td>
<td style="text-align:right;">
2.050
</td>
<td style="text-align:right;">
0.043
</td>
</tr>
</tbody>
</table>
<p>If we were to estimate our statistical power based off of these two simulations, we’d calculate it to be 50%, because 1/2 of our simulations yielded a decision to reject our null hypothesis (and our null hypothesis is indeed false). This would be a terrible estimate of power, though! We need to simulate the same analysis many times in order to actually get a good estimate for power.</p>
<hr />
</div>
<div id="simulating-power-for-one-analysis" class="section level1">
<h1>Simulating power for one analysis</h1>
<p>We’ll start by clearing our working directory. You could alternatively restart <code>R</code>.</p>
<pre class="r"><code>rm(list=ls())</code></pre>
<p>Next, let’s decide what our <code>alpha</code>, or the Type I error rate we’re willing to accept, should be. This is usually <code>0.05</code>. We will also set our <code>n</code>umber of <code>sim</code>ulation<code>s</code> to be <code>500</code>.</p>
<pre class="r"><code>alpha &lt;- .05
nsims &lt;- 500</code></pre>
<p>Next, we need to initiate an empty object to hold the results of our simulations. It’s good practice to think about what information you actually want to save from each simulation run. In this case, I am only concerned with whether the p-value of my regression is less than my <code>alpha</code>. Therefore, I initiate an empty vector to hold my <code>sig</code>nificance decision after every simulation.</p>
<pre class="r"><code>sig &lt;- c()</code></pre>
<p>Next, let’s generate the fixed parts of our simulation, like sample size, population mean, true effect size, and treatment assignments.</p>
<pre class="r"><code>n &lt;- 100
mu &lt;- 50
sd &lt;- 10
delta &lt;- 5
A &lt;- rep(c(0, 1), each = n / 2) </code></pre>
<p>Now it’s time to simulate!</p>
<p>When I learn something new involving iteration, it’s often <em>really</em> helpful for me to see it in a for-loop instead of a function. For this reason I’m showing my simulation examples first in a for-loop, but just below you’ll find the equivalent code in <code>lapply</code> and <code>purrr</code>.</p>
<p>This for-loop is saying that every time we run a simulation, we’re going to generate new data (here, just a new outcome), save that data to a tibble and fit a linear model, pull the p-value for <code>A</code> from the fit object, and then save in our <code>sig</code>nificance vector whether or not the p-value was less than our <code>alpha</code>.</p>
<pre class="r"><code>for (i in 1:nsims){
  Y &lt;- rnorm(n, mean = mu, sd = sd) + A*delta
  dat &lt;- tibble(A, Y)
  fit &lt;- lm(Y~A, data=dat)
  p_val &lt;- fit %&gt;% tidy %&gt;% filter(term == &quot;A&quot;) %&gt;% pull(p.value)
  sig[i] &lt;- p_val &lt;= alpha
}</code></pre>
<p>After running that for-loop we have a <code>sig</code>nificance vector, which has the same length as our number of simulations, and tells us whether we rejected the null hypothesis at each simulation.</p>
<pre class="r"><code>print(head(sig))</code></pre>
<p>[1] TRUE TRUE TRUE TRUE TRUE FALSE</p>
<p>So, that means to calculate our power, we just need to calculate the proportion of times we rejected the null hypothesis (since our null hypothesis that the treatment effect is zero, is in fact false).</p>
<p>That’s easy, we take the mean!</p>
<pre class="r"><code>power &lt;- mean(sig)
power</code></pre>
<p>[1] 0.722</p>
<p>So we interpret the result of our power simulation as “with treatment assigned equally and randomly to <code>n=100</code> observations, and a true treatment effect size of <code>5</code> on a population mean of <code>50</code> with a standard deviation of <code>10</code>, our simple linear regression analysis has 72% power to detect the true treatment effect.”</p>
<p>The equivalent way to do this using <code>lapply</code> or <code>purrr</code> would be to make a function containing everything in your for-loop before you save the relevant power information. Let’s clear our working directory and see what that function would look like.</p>
<pre class="r"><code>rm(list=ls())</code></pre>
<pre class="r"><code>slr_sig &lt;- function(n, mu, sd, delta, alpha){
  A &lt;- rep(c(0,1), each=n/2)
  Y &lt;- rnorm(n, mean = mu, sd = sd) + A*delta
  dat &lt;- tibble(A, Y)
  fit &lt;- lm(Y~A, data=dat)
  p_val &lt;- fit %&gt;% tidy %&gt;% filter(term == &quot;A&quot;) %&gt;% pull(p.value)
  return(p_val &lt;= alpha)
}</code></pre>
<p>Then, we can apply or map our function over however many simulations we want to do, and every time it will return whether or not our p-value was less than our alpha.</p>
<p>Using <code>purrr</code>’s <code>map()</code> or base <code>R</code>’s <code>lapply()</code>, we run our new <code>slr_sig</code> function <code>nsims</code> times. We can then unlist our results (since both functions output a list), and take the mean of that <code>sig</code>nificance vector to get our power, just as we did with the for-loop.</p>
<pre class="r"><code>nsims &lt;- 500
sig &lt;- map(1:nsims, ~slr_sig(n=100, mu=50, sd=10, delta=5, alpha=.05)) %&gt;% unlist()
mean(sig)</code></pre>
<p>[1] 0.646</p>
<pre class="r"><code>sig &lt;- lapply(1:nsims, function(i) slr_sig(n=100, mu=50, sd=10, delta=5, alpha=.05)) %&gt;% unlist()
mean(sig)</code></pre>
<p>[1] 0.692</p>
<p>If we were to increase our simulations, our power estimates would gradually converge.</p>
</div>
<div id="simulating-the-power-curve-over-sample-size" class="section level1">
<h1>Simulating the power curve over sample size</h1>
<p>In the introduction at the beginning of this post, we discussed the four main aspects of power. Let’s fix our effect size to remain 5, but vary our sample size <code>n</code>.</p>
<p>We can do this in a nesting for-loop by just wrapping a <code>j</code>th element for <code>n</code> around our previous for-loop. At the end of every <code>i</code>th iteration we’ll save the mean of the <code>sig</code>nificance vector for that <code>n</code> size and then we can look at the estimates for <code>power</code> for every <code>n</code> size` in a table or graph.</p>
<pre class="r"><code>alpha &lt;- .05 # type I error rate
sims &lt;- 500 # number of simulations
sign &lt;- c() # an empty vector to hold the results of the significance test
n_sizes &lt;- seq(10, 200, by=10)
power &lt;- c()

for (j in 1:length(n_sizes)){
  n &lt;- n_sizes[j]
  for(i in 1:sims){
    mu &lt;- 50 # population mean of controls
    sd &lt;- 10 # standard deviation of the population
    delta &lt;- 5 # treatment effect size 
    A &lt;- rep(c(0,1), each=n/2) # treatment assignments, assuming equal group sizes
    Y &lt;- rnorm(n, mean = mu, sd = sd) + A*delta
    dat &lt;- tibble(A, Y)
    fit &lt;- lm(Y~A, data=dat)
    p_val &lt;- summary(fit)$coefficients[2,4] # save the p-value
    sign[i] &lt;- p_val &lt;= alpha # to save whether the p-value is less than .05
  }
  power[j] &lt;- mean(sign)
}</code></pre>
<pre class="r"><code>p_curve &lt;- tibble(n_sizes, power)
kable(p_curve)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:right;">
n_sizes
</th>
<th style="text-align:right;">
power
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0.118
</td>
</tr>
<tr>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
0.186
</td>
</tr>
<tr>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
0.244
</td>
</tr>
<tr>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
0.298
</td>
</tr>
<tr>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
0.428
</td>
</tr>
<tr>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
0.514
</td>
</tr>
<tr>
<td style="text-align:right;">
70
</td>
<td style="text-align:right;">
0.568
</td>
</tr>
<tr>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
0.646
</td>
</tr>
<tr>
<td style="text-align:right;">
90
</td>
<td style="text-align:right;">
0.652
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
0.718
</td>
</tr>
<tr>
<td style="text-align:right;">
110
</td>
<td style="text-align:right;">
0.718
</td>
</tr>
<tr>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
0.800
</td>
</tr>
<tr>
<td style="text-align:right;">
130
</td>
<td style="text-align:right;">
0.804
</td>
</tr>
<tr>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
0.872
</td>
</tr>
<tr>
<td style="text-align:right;">
150
</td>
<td style="text-align:right;">
0.880
</td>
</tr>
<tr>
<td style="text-align:right;">
160
</td>
<td style="text-align:right;">
0.852
</td>
</tr>
<tr>
<td style="text-align:right;">
170
</td>
<td style="text-align:right;">
0.890
</td>
</tr>
<tr>
<td style="text-align:right;">
180
</td>
<td style="text-align:right;">
0.942
</td>
</tr>
<tr>
<td style="text-align:right;">
190
</td>
<td style="text-align:right;">
0.934
</td>
</tr>
<tr>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0.938
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>ggplot(p_curve, aes(n_sizes, power)) +
  geom_line() + 
  labs(x=&quot;Sample Size (n)&quot;, y=&quot;Power&quot;,
       title=&quot;Power Curve for Linear Regression of a Binary Treatment&quot;) +
  ylim(0,1) +
  geom_hline(yintercept = .8, linetype=&quot;dashed&quot;) + theme_classic()</code></pre>
<p><img src="/blog/power-sims/power-sims_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Alternatively, and admittedly in a much cleaner fashion, we can use our previous function and just add an argument for <code>n</code>. Then, we can use another <code>for-loop</code>, or, better yet, an iterative function like <code>map</code>.</p>
<p>Sometimes we want to know what our power will be</p>
<pre class="r"><code>slr_n_sig &lt;- function(n, mu, sd, delta, alpha){
  A &lt;- rep(c(0,1), each=n/2)
  Y &lt;- rnorm(n, mean = mu, sd = sd) + A*delta
  dat &lt;- tibble(A, Y)
  fit &lt;- lm(Y~A, data=dat)
  p_val &lt;- fit %&gt;% tidy %&gt;% filter(term == &quot;A&quot;) %&gt;% pull(p.value)
  return(tibble(n = n, sig = p_val &lt;= alpha))
}

map(1:2, ~imap(c(100,200), ~slr_n_sig(n=.x, mu=50, sd=10, delta=5, alpha=.05)))</code></pre>
<p>[[1]]
[[1]][[1]]
# A tibble: 1 x 2
n sig<br />
<dbl> <lgl>
1 100 FALSE</p>
<p>[[1]][[2]]
# A tibble: 1 x 2
n sig<br />
<dbl> <lgl>
1 200 TRUE</p>
<p>[[2]]
[[2]][[1]]
# A tibble: 1 x 2
n sig<br />
<dbl> <lgl>
1 100 FALSE</p>
<p>[[2]][[2]]
# A tibble: 1 x 2
n sig<br />
<dbl> <lgl>
1 200 TRUE</p>
<pre class="r"><code>rm(list=ls()) 
alpha &lt;- .05 # type I error rate
sims &lt;- 500 # number of simulations
sign &lt;- c() # an empty vector to hold the results of the significance test
n_sizes &lt;- seq(10, 200, by=10)
power &lt;- c()

for (j in 1:length(n_sizes)){
  n &lt;- n_sizes[j]
  for(i in 1:sims){
    mu &lt;- 50 # population mean of controls
    sd &lt;- 10 # standard deviation of the population
    delta &lt;- 5 # treatment effect size 
    A &lt;- rep(c(0,1), each=n/2) # treatment assignments, assuming equal group sizes
    Y &lt;- rnorm(n, mean = mu, sd = sd) + A*delta
    dat &lt;- tibble(A, Y)
    fit &lt;- lm(Y~A, data=dat)
    p_val &lt;- summary(fit)$coefficients[2,4] # save the p-value
    sign[i] &lt;- p_val &lt;= alpha # to save whether the p-value is less than .05
  }
  power[j] &lt;- mean(sign)
}

p_curve &lt;- tibble(n_sizes, power)
kable(p_curve)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:right;">
n_sizes
</th>
<th style="text-align:right;">
power
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0.108
</td>
</tr>
<tr>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
0.208
</td>
</tr>
<tr>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
0.258
</td>
</tr>
<tr>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
0.354
</td>
</tr>
<tr>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
0.402
</td>
</tr>
<tr>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
0.486
</td>
</tr>
<tr>
<td style="text-align:right;">
70
</td>
<td style="text-align:right;">
0.522
</td>
</tr>
<tr>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
0.576
</td>
</tr>
<tr>
<td style="text-align:right;">
90
</td>
<td style="text-align:right;">
0.664
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
0.710
</td>
</tr>
<tr>
<td style="text-align:right;">
110
</td>
<td style="text-align:right;">
0.736
</td>
</tr>
<tr>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
0.814
</td>
</tr>
<tr>
<td style="text-align:right;">
130
</td>
<td style="text-align:right;">
0.828
</td>
</tr>
<tr>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
0.814
</td>
</tr>
<tr>
<td style="text-align:right;">
150
</td>
<td style="text-align:right;">
0.876
</td>
</tr>
<tr>
<td style="text-align:right;">
160
</td>
<td style="text-align:right;">
0.906
</td>
</tr>
<tr>
<td style="text-align:right;">
170
</td>
<td style="text-align:right;">
0.888
</td>
</tr>
<tr>
<td style="text-align:right;">
180
</td>
<td style="text-align:right;">
0.920
</td>
</tr>
<tr>
<td style="text-align:right;">
190
</td>
<td style="text-align:right;">
0.932
</td>
</tr>
<tr>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0.934
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>ggplot(p_curve, aes(n_sizes, power)) +
  geom_line() + 
  labs(x=&quot;Sample Size (n)&quot;, y=&quot;Power&quot;,
       title=&quot;Power Curve for Linear Regression of a Binary Treatment&quot;) +
  ylim(0,1) +
  geom_hline(yintercept = .8, linetype=&quot;dashed&quot;) + theme_classic()</code></pre>
<p><img src="/blog/power-sims/power-sims_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
</div>
<div id="simulating-power-curves-for-many-sample-and-effect-sizes" class="section level1">
<h1>Simulating power curves for many sample and effect sizes</h1>
<pre class="r"><code># Vary the sample and effect sizes ------------------------------------------

rm(list=ls()) 
alpha &lt;- .05 # type I error rate
sims &lt;- 200 # number of simulations
sign &lt;- c() # an empty vector to hold the results of the significance test
n_sizes &lt;- seq(10, 200, by=10)
deltas &lt;- c(3,5,8)
power_table &lt;- tibble(delta = rep(deltas, each=length(n_sizes)),
                      n = rep(n_sizes, times = length(deltas)),
                      power = rep(NA)) # table to keep track of our power
count &lt;- 0 # to keep track of each n and delta combo

for (k in 1:length(deltas)){
  delta &lt;- deltas[k]
for (j in 1:length(n_sizes)){
  n &lt;- n_sizes[j]
  count &lt;- count+1
for (i in 1:sims){
    mu &lt;- 50 # population mean of controls
    sd &lt;- 10 # standard deviation of the population
    A &lt;- rep(c(0,1), each=n/2) # treatment assignments, assuming equal group sizes
    Y &lt;- rnorm(n, mean = mu, sd = sd) + A*delta
    dat &lt;- tibble(A, Y)
    fit &lt;- lm(Y~A, data=dat)
    p_val &lt;- summary(fit)$coefficients[2,4] # save the p-value
    sign[i] &lt;- p_val &lt;= alpha # to save whether the p-value is less than .05
}
  power_table[count,&quot;power&quot;] &lt;- mean(sign) # record power for each delta and n combo
  print(count) # helpful to check on sim status
}
}</code></pre>
<p>[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60</p>
<pre class="r"><code>kable(head(power_table))</code></pre>
<table>
<thead>
<tr>
<th style="text-align:right;">
delta
</th>
<th style="text-align:right;">
n
</th>
<th style="text-align:right;">
power
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0.050
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
0.070
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
0.175
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
0.195
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
0.170
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
0.195
</td>
</tr>
</tbody>
</table>
<pre class="r"><code># Plot the three different power curves (one for each delta)
ggplot(power_table, aes(n, power, col=factor(delta), group=factor(delta))) +
  geom_line() + 
  labs(x=&quot;Sample Size (n)&quot;, y=&quot;Power&quot;,
       title=&quot;Power Curve for Linear Regression of a Binary Treatment&quot;,
       col = &quot;Effect Size&quot;) +
  ylim(0,1) +
  geom_hline(yintercept = .8, linetype=&quot;dashed&quot;) +
  theme_classic()</code></pre>
<p><img src="/blog/power-sims/power-sims_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>#Full code without explanations</p>
</div>
