---
title: "The Key to Learning Causal Inference"
author: "Katherine Hoffman"
date: 2020-09-12T21:13:14-05:00
categories: ["statistics"]
draft: true
math: true
tags: ["causal inference"]
output: 
  html_document:
    toc: true
    toc_float: true
    smart: false
    print_df: paged
---

I've been trying to learn causal inference for the past year and a half. Not in the way people say, "I've been trying to learn guitar" or "I've been trying to learn Japanese", either. Trying as in, spent too many pre-pandemic Sundays at crowded coffee shops with a backpack causal inference books, and even dragged a binder of notes to a vacation in Costa Rica...

![](/img/causal_at_beach.jpg)
I'm no expert in causal inference, but at this point I at least have an opinion on the best way to *learn* causal inference. It's actually a pretty simple concept, but I was really spinning my wheels until I learned it. So, in case you're early into your causal inference journey and haven't discovered it yet:

> I believe the key to learning (and applying) causal inference is to always keep **identification** separate from **estimation**.

Now what does *that* mean!? Broadly, **identification means figuring out whether you can write a causal estimand of interest in terms of data** (i.e., in forms of expectations of random variables).

A **causal estimand** is just some summary quantity that would be interesting to evaluate in the system you're studying. A few common causal estimands are the Average Treatment Effect and the Conditional Average Treatment Effect. There are many, many more though, such as the Dose Response Curve, Causal Odds Ratio, Causal Risk Ratio, and Marginal Structural Model.

To determine whether you can identify your causal estimand of interest in your system of study and with the data you have, careful thought is required. It's the stage of a problem when you, as a statistician, sit down and talk with subject matter experts about the precise question they'd like to answer. You may draw *Directed Acyclic Graphs* (DAGs) or *Single World Intervention Graphs* (SWIGs), or write out the *Non Parametric Structural Equations* of the system.

These tools will help you evaluate some of the main requirements of causal inference: for the causal estimand of interest to be identified, you must satisfy causal assumptions of *positivity*, *exchangeability*, and *ignorability*, while still avoiding the usual pitfalls in statistics like *selection bias* and *unmeasured confounding*.

You'll eventually determine whether the causal estimand is possible to write out in terms of your data. For example, if your goal is to identify the Average Treatment Effect (ATE), i.e. the mean difference in outcomes between the treated and untreated in a hypothetical world where everyone *could* get each treatment $A$, your identification of the ATE, $\theta$, may look like:

$\theta = E_W[E[Y|A=1,W]-E[Y|A=0,W]]$

where $W$ is a vector of confounding variables that affect both $A$ and $Y$.

Once 

Everything I've mentioned so far is part of the **identification** side of causal inference. I think of it as the non-data side, because we are not yet dealing with data when we think about the study design, causal estimand, and whether the causal conditions are reasonable to assume. You should never be thinking about **estimation methods** until you've determined whether your causal estimand can be identified.

![](/img/causal_comic.jpg)


Once you've *identified* your WHAT, or your estimand of interest, then you can start thinking about HOW you're going to *estimate* that estimand. There are many statistical estimation methods to estimate the same causal effect of interest.

My favorite way to think about this is through a little graph like this. On the left, there are three causal estimands, or estimands of interest. On the top, we can see six different ways you might try to estimate any of these causal estimands of interest. Each of the estimation methods have pros and cons. 

$Odds ratio = E[Y]$

$Relative risk = E[Y]$

$\mathrm{ATE} = E[Y]$






A common example is figuring out whether the Average Treatment Effect (ATE), or the difference in outcomes if everyone were to receive the exposure compared to if everyone had not received the exposure

$\theta^* = E[E[Y|A=1,W]-E[Y|A=0,W]]$


Sure, propensity scores are part of causal inference, but they're part of the *estimation* side of causal inference. A propensity score can't fix a research question with a causal estimand that does not meet causal assumptions.

Causal 


I think causal inference is the most interesting topic in all of statistics-- I think it's so cool that sometimes I make really dweeby comics about it:










