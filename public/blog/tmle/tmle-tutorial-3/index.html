<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.4.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Katherine Hoffman">

  
  
  
    
  
  <meta name="description" content="A beginner’s guide to understanding the Targeted Maximum Likelihood Estimation (TMLE) algorithm.
 TLDR  The general form of Targeted Maximum Likelihood Estimation (TMLE) allows you to estimate a statistical estimand of interest using:
the expected outcome of an individual, given the treatment they received and their baseline confounders
 the probability an individual received the treatment of interest, given their baseline confounders (propensity score)
  These estimates can come from flexible, data-adaptive statistical models we commonly categorize as machine learning, allowing us to place minimal assumptions on the distribution of the data.">

  
  <link rel="alternate" hreflang="en-us" href="/blog/tmle/tmle-tutorial-3/">

  


  

  
  
  
  <meta name="theme-color" content="#614f79">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.93ba0f8058c7a032bde93225bfbbb6b6.css">

  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-136820093-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="https://www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/blog/tmle/tmle-tutorial-3/">

  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@rkatlady">
  <meta property="twitter:creator" content="@rkatlady">
  
  <meta property="og:site_name" content="KHstats">
  <meta property="og:url" content="/blog/tmle/tmle-tutorial-3/">
  <meta property="og:title" content="A Visual Guide to the Targeted Maximum Likelihood Estimation (TMLE) Algorithm | KHstats">
  <meta property="og:description" content="A beginner’s guide to understanding the Targeted Maximum Likelihood Estimation (TMLE) algorithm.
 TLDR  The general form of Targeted Maximum Likelihood Estimation (TMLE) allows you to estimate a statistical estimand of interest using:
the expected outcome of an individual, given the treatment they received and their baseline confounders
 the probability an individual received the treatment of interest, given their baseline confounders (propensity score)
  These estimates can come from flexible, data-adaptive statistical models we commonly categorize as machine learning, allowing us to place minimal assumptions on the distribution of the data."><meta property="og:image" content="/img/icon-192.png">
  <meta property="twitter:image" content="/img/icon-192.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-10-10T21:13:14-05:00">
    
    <meta property="article:modified_time" content="2020-10-10T21:13:14-05:00">
  

  


  





  <title>A Visual Guide to the Targeted Maximum Likelihood Estimation (TMLE) Algorithm | KHstats</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">KHstats</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#hero"><span>About</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#blogs"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
            
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="https://scholar.google.com/citations?user=73RvTUoAAAAJ&amp;hl=en" target="_blank" rel="noopener"><span>Publications</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        

      </ul>

    </div>
  </div>
</nav>


  <article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">A Visual Guide to the Targeted Maximum Likelihood Estimation (TMLE) Algorithm</h1>

  

  
    



<meta content="2020-10-10 21:13:14 -0500 -0500" itemprop="datePublished">
<meta content="2020-10-10 21:13:14 -0500 -0500" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>Oct 10, 2020</time>
  </span>
  

  

  

  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/categories/statistics/">statistics</a>, <a href="/categories/r/">R</a></span>
  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/blog/tmle/tmle-tutorial-3/&amp;text=A%20Visual%20Guide%20to%20the%20Targeted%20Maximum%20Likelihood%20Estimation%20%28TMLE%29%20Algorithm" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/blog/tmle/tmle-tutorial-3/&amp;t=A%20Visual%20Guide%20to%20the%20Targeted%20Maximum%20Likelihood%20Estimation%20%28TMLE%29%20Algorithm" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook-f"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=A%20Visual%20Guide%20to%20the%20Targeted%20Maximum%20Likelihood%20Estimation%20%28TMLE%29%20Algorithm&amp;body=/blog/tmle/tmle-tutorial-3/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/blog/tmle/tmle-tutorial-3/&amp;title=A%20Visual%20Guide%20to%20the%20Targeted%20Maximum%20Likelihood%20Estimation%20%28TMLE%29%20Algorithm" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=A%20Visual%20Guide%20to%20the%20Targeted%20Maximum%20Likelihood%20Estimation%20%28TMLE%29%20Algorithm%20/blog/tmle/tmle-tutorial-3/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=/blog/tmle/tmle-tutorial-3/&amp;title=A%20Visual%20Guide%20to%20the%20Targeted%20Maximum%20Likelihood%20Estimation%20%28TMLE%29%20Algorithm" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>


  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      


<blockquote>
<p>A beginner’s guide to understanding the Targeted Maximum Likelihood Estimation (TMLE) algorithm.</p>
</blockquote>
<hr />
<div id="tldr" class="section level1">
<h1>TLDR</h1>
<ul>
<li><p>The general form of Targeted Maximum Likelihood Estimation (TMLE) allows you to <strong>estimate a statistical estimand of interest using</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>the expected outcome of an individual, given the treatment they received and their baseline confounders</p></li>
<li><p>the probability an individual received the treatment of interest, given their baseline confounders (propensity score)</p></li>
</ol></li>
<li><p>These estimates can come from <strong>flexible, data-adaptive statistical models</strong> we commonly categorize as machine learning, allowing us to place <strong>minimal assumptions on the distribution of the data</strong>. However, unlike estimates normally obtained from data-adaptive algorithms, the <strong>final TMLE estimate will still have valid standard errors for statistical inference</strong>.</p></li>
</ul>
<hr />
</div>
<div id="the-motivation-for-tmle" class="section level1">
<h1>The Motivation for TMLE</h1>
<p>The <em>two cultures of statistical modeling</em> Leo Breiman described in 2001 is still a pervasive issue in statistics and data science. On one hand, we are rapidly developing new, flexible statistical models for predicting outcomes. These flexible, data-adaptive algorithms – often referred to as <strong>machine learning</strong> (ML) – are excellent at handling data with many predictors and complex, non-linear relationships.</p>
<p>However, machine learning algorithms are optimized for predicting an outcome, and they yield the wrong bias-variance tradeoff for any particular predictor, or treatment, effect estimate of interest. This makes it impossible to obtain valid standard errors to answer questions about individual effects of interest.</p>
<p>Meanwhile, the widespread methods for answering questions about effects of individual variables on outcomes of interest continue to be parametric models with strong and often entirely unrealistic assumptions like linear and logistic regression. This is because these models balance the bias-variance tradeoff between the outcome and all predictors, and thus yield valid standard errors for statistical inference.</p>
<p>While I was earning my MS in Biostatistics, it seemed to me like there were two distinct camps with their own set of modeling tools. If your goal was to <em>predict</em>, you could use cool “black box” models like random forests, neural nets, gradient boosting, etc. However, if you needed to <em>infer</em>, you were limited to generalized linear models, Cox proportional hazard models, and generalized estimating equations.</p>
<p>The ideal solution was obvious: use machine learning to obtain effect estimates which somehow still have valid standard errors for statistical inference. However, it wasn’t until I began my first job as a biostatistician that I began learning there are already well-developed methods like this. Semi-parametric estimation methods belong somewhere in the middle of these two camps I’d created in my mental understanding of statistics: they allow the use of data-adaptive ML models, while still yielding estimates of an individual predictor, or treatment, of interest with valid standard errors for inference.</p>
<p><strong>TMLE is one such semi-parametric estimation method.</strong> It’s a bit complicated, but in this post I’ll attempt to explain what the TMLE algorithm does in a way that I think I would have understood best when I first began reading about it two years ago.</p>
</div>
<div id="the-motivation-for-a-visual-guide" class="section level1">
<h1>The Motivation for a Visual Guide</h1>
<p>As an applied MS-level statistician without a strong background in mathematical theory, I found all resources to learn TMLE to be a bit (okay, a lot) daunting for quite a while. It’s been my goal for several months to curate a starter guide for TMLE for someone who learns more like me: in pictures and lots of words.</p>
<p>I hope you find the way I think about the algorithm useful, but if not, I hope you go seek out some of the references I’ve listed, because I think TMLE and other semiparametric estimation methods are super important and interesting (and also <em>the future</em>).</p>
<html>
<head>
<title>
HTML Image as link
</title>
</head>
<body>
<a href="https://github.com/hoffmakl/CI-visual-guides/blob/master/visual-guides/TMLE.pdf">
<img alt="cheatsheet" src="/img/TMLE.jpg"
         width=100%">
<figcaption>
<em>The Visual Guide…</em> <a href="">I</a> interpret statistical algorithms very visually, and the way I learned TMLE was by drawing each step out with pseudo-<code>R</code> code. I eventually formalized that thought process into a one page “cheat sheet” in case anyone else learns like this.
</figcaption>
</a>
</body>
</html>
<!-- This post contains a step-by-step demonstration of TMLE with `R` code and simulated data. I may tackle the highlights of *why* and *how* TMLE works in future posts, but if you're interested in the meantime, check out my references section at the end. Before I discuss the algorithm, two small background notes: -->
<div id="notation-and-data" class="section level3">
<h3>Notation and Data</h3>
<p>I’ve tried to use the same notation in this post as is commonly used in the <a href="#references">TMLE literature</a> to make it easier to move from one resource to another. I’ve also used the same data generating code as Miguel Angel Luque Fernandez used in his <a href="https://migariane.github.io/TMLE.nb.html">excellent and slightly more technical tutorial on TMLE</a>, so that you can move back and forth between our tutorials, if you wish.</p>
</div>
<div id="superlearning" class="section level3">
<h3>Superlearning</h3>
<p>I use the ensemble learning method <strong>superlearning</strong> (also known as “stacking”) to demonstrate TMLE. This is because superlearning is theoretically and empirically proven to yield the best results in TMLE.</p>
<p>For a tutorial on superlearning, you can check out my <a href="www.khstats.com/sl/superlearning">previous blog post</a>. If you’re new to superlearning/stacking, the necessary knowledge for this post is that it allows you to combine many statistical learning algorithms for prediction. When I use <code>SuperLearner()</code> in the following example code, I could have used <code>glm()</code>, <code>randomForest()</code>, or any other parametric or non-parametric supervised learning algorithm.</p>
</div>
</div>
<div id="the-tmle-algorithm" class="section level1">
<h1>The TMLE Algorithm</h1>
<div id="initial-set-up" class="section level3">
<h3>Initial set up</h3>
<p>Let’s load the libraries we’ll need for analysis and set a seed.</p>
<pre class="r"><code>library(tidyverse) # for data manipulation
library(kableExtra) # for table printing
library(SuperLearner) # for ensemble learning

set.seed(7) # for reproducible results</code></pre>
<p>Next, let’s simulate a data set for demonstration of the algorithm. This data will have a very simple structure: a binary treatment, <span class="math inline">\(A\)</span>, binary outcome, <span class="math inline">\(Y\)</span>, and four confounders: <span class="math inline">\(W_1\)</span>, <span class="math inline">\(W_2\)</span>, <span class="math inline">\(W_3\)</span>, and <span class="math inline">\(W_4\)</span>.</p>
<p><img src="/img/tmle/1_data_structure.png" style="width:80.0%" /></p>
<pre class="r"><code>generate_data &lt;- function(n){ # using data generating code from Miguel Angel Luque Fernandez&#39; tutorial; more on that later
    W1 &lt;- rbinom(n, size=1, prob=0.5)
    W2 &lt;- rbinom(n, size=1, prob=0.65)
    W3 &lt;- round(runif(n, min=0, max=4), digits=3)
    W4 &lt;- round(runif(n, min=0, max=5), digits=3)
    A  &lt;- rbinom(n, size=1, prob= plogis(-0.4 + 0.2*W2 + 0.15*W3 + 0.2*W4 + 0.15*W2*W4))
    Y &lt;- rbinom(n, size=1, prob= plogis(-1 + A -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4))
    return(tibble(W1, W2, W3, W4, A, Y))
}

n &lt;- 100
dat_obs &lt;- generate_data(n) # generate a data set with n observations

kable(head(dat_obs), digits=2, caption = &quot;Simulated data set.&quot;)</code></pre>
<table>
<caption>
<span id="tab:unnamed-chunk-2">Table 1: </span>Simulated data set.
</caption>
<thead>
<tr>
<th style="text-align:right;">
W1
</th>
<th style="text-align:right;">
W2
</th>
<th style="text-align:right;">
W3
</th>
<th style="text-align:right;">
W4
</th>
<th style="text-align:right;">
A
</th>
<th style="text-align:right;">
Y
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2.79
</td>
<td style="text-align:right;">
1.80
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3.50
</td>
<td style="text-align:right;">
3.25
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2.89
</td>
<td style="text-align:right;">
4.32
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1.77
</td>
<td style="text-align:right;">
1.68
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1.87
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3.46
</td>
<td style="text-align:right;">
0.77
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table>
<p>As an estimation algorithm, TMLE can estimate many different statistical estimands of interest. In this example, our statistical estimand will be the mean difference in outcomes between those who received the treatment and those who did not, adjusting for confounders.</p>
<p>Under causal inference assumptions, this could be identifiable as the Average Treatment Effect, or ATE. Although TMLE cannot be considered a method for causal inference by itself, it is often used when causal interpretations are desired because of various attractive statistical properties. I’ll discuss more later in this post, but for now, let’s call our statistical estimand, <span class="math inline">\(\Psi\)</span>, the ATE, and define it as:</p>
<p><span class="math display">\[\Psi = ATE = E_W[E[Y|A=1,W] - E[Y|A=0,W]]\]</span></p>
<p>At this point in set-up, we should also pick our statistical learning algorithms to combine when we use the superlearner to estimate the expected outcome and probability of treatment. Let’s use LASSO (<code>glmnet</code>), random forests (<code>ranger</code>), and Multivariate Adaptive Regression Splines (MARS) (<code>earth</code>).</p>
<pre class="r"><code>sl_libs &lt;- c(&#39;SL.glmnet&#39;, &#39;SL.ranger&#39;, &#39;SL.earth&#39;) # a library of machine learning algorithms (penalized regression, random forests, and multivariate adaptive regression splines)</code></pre>
</div>
</div>
<div id="step-1-estimate-the-outcome" class="section level1">
<h1>Step 1: Estimate the Outcome</h1>
<p>The very first step of TMLE is to fit a statistical model to estimate the expected value of the outcome using treatment and confounders as predictors.</p>
<p><img src="/img/tmle/2_outcome_fit.png" style="width:70.0%" /></p>
<p><span class="math display">\[Q(A,W) = \mathrm{E}[Y|A,W]\]</span></p>
<p>We’ll use the <code>SuperLearner()</code> function to fit a weighted combination of multiple machine learning models (defined earlier in <code>sl_libs</code>). This function takes the outcome <code>Y</code> as a vector and a data frame <code>X</code> as predictors.</p>
<pre class="r"><code>Y &lt;- dat_obs$Y
X &lt;- dat_obs %&gt;% select(-Y) # remove the outcome to make a matrix of predictors (A, W1, W2, W3, W4) for SuperLearner
Q &lt;- SuperLearner(Y = Y, # Y is the outcome vector
                  X = X, # X is the matrix of predictors
                  family=binomial(), # specify we have a binary outcome
                  SL.library = sl_libs) # specify our superlearner library of LASSO, RF, and MARS</code></pre>
<pre><code>## Loading required namespace: glmnet</code></pre>
<pre><code>## Loading required namespace: earth</code></pre>
<pre><code>## Loading required namespace: ranger</code></pre>
<p>Then, we should predict the outcome for every observation under three different scenarios:</p>
<p><strong>1. If every observation received the treatment they <em>actually</em> received.</strong></p>
<p>We can get this expected outcome by simply calling <code>predict()</code> on the model fit, and not specifying any new data.</p>
<p><img src="/img/tmle/3_QA.png" style="width:50.0%" /></p>
<p><span class="math display">\[\hat{Q}(A,W) = \mathrm{\hat{E}}[Y|A,W]\]</span></p>
<pre class="r"><code>Q_A &lt;- as.vector(predict(Q)$pred) # obtain predictions for everyone using the treatment they actually received</code></pre>
<p><strong>2. If every observation received the treatment.</strong></p>
<p><img src="/img/tmle/4_Q1.png" style="width:80.0%" /></p>
<p><span class="math display">\[\hat{Q}(1,W) = \mathrm{\hat{E}}[Y|1,W]\]</span></p>
<p>To do this, we’ll first need to create a data set where every observation received the treatment of interest, whether they actually did or not. Then we can call the <code>predict()</code> function on that data set.</p>
<pre class="r"><code>X_A1 &lt;- X %&gt;% mutate(A = 1)  # data set where everyone received treatment
Q_1 &lt;- as.vector(predict(Q, newdata = X_A1)$pred) # predict on that everyone-exposed data set</code></pre>
<p><strong>3. If every observation received the control.</strong></p>
<p><img src="/img/tmle/5_Q1.png" style="width:80.0%" /></p>
<p><span class="math display">\[\hat{Q}(0,W) = \mathrm{\hat{E}}[Y|0,W]\]</span>
Similarly, we create a data set where every observation did not receive the treatment of interest, whether they actually did or not, and call the <code>predict()</code> function again.</p>
<pre class="r"><code>X_A0 &lt;- X %&gt;% mutate(A = 0) # data set where no one received treatment
Q_0 &lt;- as.vector(predict(Q, newdata = X_A0)$pred)</code></pre>
<p>Let’s create a new data frame, <code>dat_tmle</code>, to hold the three vectors we’ve created so far, along with the treatment status <span class="math inline">\(A\)</span> and observed outcome <span class="math inline">\(Y\)</span>. Notice that when <span class="math inline">\(A=1\)</span>, the expected outcome <span class="math inline">\(Q(W,A)\)</span> equals the expected outcome under treatment <span class="math inline">\(Q(W,1)\)</span> and when <span class="math inline">\(A=0\)</span>, the expected outcome <span class="math inline">\(Q(W,A)\)</span> equals the expected outcome under no treatment <span class="math inline">\(Q(W,0)\)</span>.</p>
<pre class="r"><code>dat_tmle &lt;- tibble(Y = dat_obs$Y, A = dat_obs$A, Q_A, Q_0, Q_1)
kable(head(dat_tmle), digits=2, caption = &quot;TMLE Algorithm after Step 1&quot;)</code></pre>
<table>
<caption>
<span id="tab:unnamed-chunk-8">Table 2: </span>TMLE Algorithm after Step 1
</caption>
<thead>
<tr>
<th style="text-align:right;">
Y
</th>
<th style="text-align:right;">
A
</th>
<th style="text-align:right;">
Q_A
</th>
<th style="text-align:right;">
Q_0
</th>
<th style="text-align:right;">
Q_1
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.97
</td>
<td style="text-align:right;">
0.97
</td>
<td style="text-align:right;">
0.85
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
0.91
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
0.80
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.82
</td>
<td style="text-align:right;">
0.82
</td>
<td style="text-align:right;">
0.88
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
0.86
</td>
<td style="text-align:right;">
0.91
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.73
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
0.73
</td>
</tr>
</tbody>
</table>
<p><em>Also note that our expected outcomes are on the original outcome scale (i.e. probability, rather than the <span class="math inline">\(logit\)</span> probability).</em></p>
<p>We could stop here and just do:</p>
<p><span class="math display">\[\mathrm{\hat{E}}[Y|A=1,W]-\mathrm{\hat{E}}[Y|A=0,W]\]</span></p>
<p>to get our estimate of the ATE. This is often referred to as <strong>G-computation</strong>. However, because we’ve used machine learning to obtain our outcome estimates, they do not have the right bias-variance tradeoff for treatment (the bias-variance tradeoff is instead optimized for the outcome). Besides the potential for bias in the G-computation ATE estimate itself, we have no way to obtain valid standard errors.</p>
<p>We need to incorporate information about the treatment mechanism in order to fix the incorrect bias-variance trade-off.</p>
</div>
<div id="step-2-estimate-the-probability-of-treatment" class="section level1">
<h1>Step 2: Estimate the Probability of Treatment</h1>
<p>The next step is to estimate the probability of treatment, given confounders. This quantity is often called a <strong>propensity score</strong>, as in it gives the <em>propensity</em> that an observation will receive a treatment of interest.</p>
<p><span class="math display">\[g(W) = Pr(A=1|W)\]</span></p>
<p><img src="/img/tmle/6_treatment_fit.png" style="width:60.0%" /></p>
<p>We will fit <span class="math inline">\(g(W)\)</span> in a similar way as we fit <span class="math inline">\(Q(A,W)\)</span>, using the superlearner algorithm.</p>
<pre class="r"><code>A &lt;- dat_obs$A
X_A &lt;- dat_obs %&gt;% select(-Y, -A) # matrix of predictors that only contains the confounders W1, W2, W3, and W4

g &lt;- SuperLearner(Y = A,
                  X = X_A,
                  family=binomial(),
                  SL.library=sl_libs)</code></pre>
<p>Then we need to compute three different quantities from this <span class="math inline">\(g(W)\)</span> fit.</p>
<p><strong>1. The inverse probability of receiving treatment.</strong></p>
<p><img src="/img/tmle/7_H1.png" style="width:60.0%" /></p>
<p><span class="math display">\[H(1,W) = \frac{1}{g(W)} = \frac{1}{Pr(A=1|W)}\]</span></p>
<pre class="r"><code>H_1 &lt;- 1/predict(g)$pred</code></pre>
<p><strong>2. The negative inverse probability of not receiving treatment.</strong></p>
<p><img src="/img/tmle/8_H0.png" style="width:70.0%" /></p>
<p><span class="math display">\[H(0,W) = -\frac{1}{1-g(W)}= -\frac{1}{Pr(A=0|W)}\]</span></p>
<pre class="r"><code>H_0 &lt;- -1/(1-predict(g)$pred)</code></pre>
<p><strong>3. If the observation was treated, the inverse probability of receiving treatment, and if they were not treated, the negative inverse probability of not receiving treatment.</strong></p>
<p><img src="/img/tmle/9_HA.png" style="width:50.0%" /></p>
<p><span class="math display">\[H(A,W) = \frac{\mathrm{I}(A=1)}{Pr(A=1|W)}-\frac{\mathrm{I}(A=0)}{Pr(A=0|W)}\]</span></p>
<p>To calculate this, we’ll first add the <span class="math inline">\(H(1,W)\)</span> and <span class="math inline">\(H(0,W)\)</span> vectors to our <code>dat_tmle</code> data frame, and then we can use <span class="math inline">\(A\)</span> to assign <span class="math inline">\(H(A,W)\)</span>.</p>
<pre class="r"><code>dat_tmle &lt;- # add clever covariate data to dat_tmle
  dat_tmle %&gt;%
  bind_cols(
         H_1 = H_1,
         H_0 = H_0) %&gt;%
  mutate(H_A = case_when(A == 1 ~ H_1, # if A is 1 (treated), assign H_1
                       A == 0 ~ H_0))  # if A is 0 (not treated), assign H_0

kable(head(dat_tmle), digits=2, caption=&quot;TMLE Algorithm after Step 2&quot;)</code></pre>
<table>
<caption>
<span id="tab:unnamed-chunk-12">Table 3: </span>TMLE Algorithm after Step 2
</caption>
<thead>
<tr>
<th style="text-align:right;">
Y
</th>
<th style="text-align:right;">
A
</th>
<th style="text-align:right;">
Q_A
</th>
<th style="text-align:right;">
Q_0
</th>
<th style="text-align:right;">
Q_1
</th>
<th style="text-align:right;">
H_1
</th>
<th style="text-align:right;">
H_0
</th>
<th style="text-align:right;">
H_A
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.97
</td>
<td style="text-align:right;">
0.97
</td>
<td style="text-align:right;">
0.85
</td>
<td style="text-align:right;">
1.608060
</td>
<td style="text-align:right;">
-2.644575
</td>
<td style="text-align:right;">
-2.64
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
1.229841
</td>
<td style="text-align:right;">
-5.350826
</td>
<td style="text-align:right;">
1.23
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
1.168911
</td>
<td style="text-align:right;">
-6.920263
</td>
<td style="text-align:right;">
1.17
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.82
</td>
<td style="text-align:right;">
0.82
</td>
<td style="text-align:right;">
0.88
</td>
<td style="text-align:right;">
1.861960
</td>
<td style="text-align:right;">
-2.160146
</td>
<td style="text-align:right;">
-2.16
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
0.86
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
1.496574
</td>
<td style="text-align:right;">
-3.013800
</td>
<td style="text-align:right;">
1.50
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.73
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
0.73
</td>
<td style="text-align:right;">
1.267989
</td>
<td style="text-align:right;">
-4.731503
</td>
<td style="text-align:right;">
1.27
</td>
</tr>
</tbody>
</table>
</div>
<div id="step-3-estimate-the-fluctuation-parameter" class="section level1">
<h1>Step 3: Estimate the Fluctuation Parameter</h1>
<p>The next step is to fit a model to help us solve for a <strong>fluctuation parameter</strong>. This is the most confusing part of the whole algorithm in my opinion…</p>
<html>
<head>
<title>
HTML Image as link
</title>
</head>
<body>
<a href="">
<img alt="cheatsheet" src="/img/bear_with_me.jpg"
               style="float:right; padding-left:40px; padding-top:-30px;
         width=50%">
</a>
</body>
</html>
<p>…but it’s also the most important step! This is because the way we set up the model solves a value, <span class="math inline">\(\epsilon\)</span>, which tells us how much to change, or fluctuate, the initial estimates of the outcome. The model is a clever way of finding the <strong>efficient influence function</strong> (more on that later), which is how we’re able to get standard errors for inference even after using data-adaptive statistical learning algorithms like the superlearner.</p>
<p>Practically, we implement this step by fitting a logistic regression with only one covariate, <span class="math inline">\(H(A,W)\)</span>, and the initial outcome estimate, <span class="math inline">\(Q(A,W)\)</span>, as the intercept. The outcome in the logistic regression is the observed outcome, <span class="math inline">\(Y\)</span>.</p>
<p>Two technical points for application: since we’re fitting a logistic regression, the initial estimate <span class="math inline">\(Q(A,W)\)</span> needs to be on the <span class="math inline">\(logit\)</span> scale (so we use <code>qlogis</code> to transform the probabilities). Also, the <code>R</code> code for a fixed intercept is <code>-1 + offset(fixed_intercept)</code>.</p>
<p><img src="/img/tmle/10_logistic_regression.png" /></p>
<pre class="r"><code>glm_fit &lt;- glm(Y ~ -1 + offset(qlogis(Q_A)) + H_A, data=dat_tmle, family=binomial)</code></pre>
<p><em>Note that <strong>even when the outcome is not binary, this will still be a logistic regression</strong>.</em></p>
<p>Fitting the logistic regression is a trick to solve for the score function of our statistical estimand and thereby obtain the efficient influence function. If you’re confused about this step, please don’t panic. There’s a lot of semiparametric estimation theory behind it which I don’t want to distract from the actual algorithm.</p>
<p>Intuitively, we do this step because we know the initial outcome estimates we used machine learning models to fit have the wrong bias-variance tradeoff for estimating the effect of treatment. We’re trying to figure out how much we need to change those initial estimates of the outcome, using information about treatment, to achieve the correct bias-variance trade-off for our final statistical estimand of interest, the ATE.</p>
<p>Anyways, we need to save the coefficient from that logistic regression, which is our <span class="math inline">\(\hat{\epsilon}\)</span>:</p>
<p><img src="/img/tmle/11_epsilon.png" style="width:40.0%" /></p>
<pre class="r"><code>eps &lt;- coef(glm_fit)</code></pre>
</div>
<div id="step-4-update-the-initial-estimates-of-the-expected-outcome" class="section level1">
<h1>Step 4: Update the Initial Estimates of the Expected Outcome</h1>
<p>We’ve done all the hard parts, so now all we have to do is update our estimates of the expected outcome using our fluctuation parameter, <span class="math inline">\(\hat{\epsilon}\)</span>.</p>
<p>To do this, we need to put the expected outcome estimates on the <span class="math inline">\(logit\)</span> scale because that’s the scale we used to solve the fluctuation parameter in step 3. Then we can add <span class="math inline">\(\hat{\epsilon} \times H(A,W)\)</span>. Finally, we can put the updated estimates back on the true outcome scale (in the case of the binary outcome, probability.</p>
<p><img src="/img/tmle/12_update_Q1.png" style="width:70.0%" />
We’ll first do this for <span class="math inline">\(\hat{Q}(1,W) = \hat{E}[Y|A=1,W]\)</span>:</p>
<p><span class="math display">\[\hat{\mathrm{E}}^*[Y|A=1] = expit(logit(\mathrm{\hat{E}}[Y|A=1|W]) + \hat{\epsilon}H(A,W))\]</span></p>
<pre class="r"><code>Q_1_update &lt;- plogis(qlogis(Q_1) + eps*H_1)</code></pre>
<p><img src="/img/tmle/13_update_Q0.png" style="width:70.0%" />
The same idea applies for <span class="math inline">\(\hat{Q}(0,W) = \hat{E}[Y|A=0,W]\)</span>:</p>
<p><span class="math display">\[\hat{\mathrm{E}}^*[Y|A=0] = expit(logit(\mathrm{\hat{E}}[Y|A=0|W]) + \hat{\epsilon}H(A,W))\]</span></p>
<pre class="r"><code>Q_0_update &lt;- plogis(qlogis(Q_0) + eps*H_0)</code></pre>
</div>
<div id="step-5-compute-the-statistical-estimand-of-interest" class="section level1">
<h1>Step 5: Compute the Statistical Estimand of Interest</h1>
<p>Now that we have updated expected outcome estimates (now targeted towards treatment), we can recompute the ATE:</p>
<p><img src="/img/tmle/14_compute_ATE.png" style="width:60.0%" /></p>
<pre class="r"><code>tmle_psi &lt;- mean(Q_1_update - Q_0_update)
tmle_psi</code></pre>
<pre><code>## [1] 0.1461507</code></pre>
</div>
<div id="step-6-calculate-the-standard-errors-confidence-intervals-and-p-values" class="section level1">
<h1>Step 6: Calculate the Standard Errors, Confidence Intervals, and P-values</h1>
<p>We can now compute the influence curve of the estimate using the following equation:</p>
<p><img src="/img/tmle/15_ses.png" style="width:100.0%" /></p>
<pre class="r"><code># also get H as a vector (for Q_A_update)
H_A &lt;- dat_tmle$H_A
Q_A_update &lt;- plogis(qlogis(Q_A) + eps*H_A)

ic &lt;- (Y - Q_A_update) * H_A + Q_1_update + Q_0_update</code></pre>
<p>The influence curve is essentially a vector of points that tells us, unsurprisingly!, how much influence each observation has on estimate. It turns out we can compute the standard error with another straightforward equation:</p>
<pre class="r"><code>tmle_se &lt;- sqrt(var(ic)/nrow(dat_obs))</code></pre>
<p>Once we have the standard error, life is easy! We can get the confidence intervals and p-values and potentially reject our hypotheses.</p>
<pre class="r"><code>ci_lo &lt;- tmle_psi - 1.96*tmle_se
ci_hi &lt;- tmle_psi + 1.96*tmle_se

pval &lt;- 2 * (1 - pnorm(abs(tmle_psi / tmle_se)))</code></pre>
<p>WHEW, that was a lot! If you made it to the end, congrats! Lucky for you, we don’t actually have</p>
</div>
<div id="references" class="section level1">
<h1>References:</h1>
</div>

    </div>

    


    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/statistics/">statistics</a>
  
  <a class="badge badge-light" href="/tags/causal-inference/">causal inference</a>
  
  <a class="badge badge-light" href="/tags/r/">R</a>
  
  <a class="badge badge-light" href="/tags/lmtp/">lmtp</a>
  
  <a class="badge badge-light" href="/tags/tmle/">TMLE</a>
  
  <a class="badge badge-light" href="/tags/targeted-maximum-likelihood-estimation/">Targeted Maximum Likelihood Estimation</a>
  
  <a class="badge badge-light" href="/tags/introduction-to-tmle/">introduction to TMLE</a>
  
  <a class="badge badge-light" href="/tags/targeted-learning/">targeted learning</a>
  
</div>



    
      








  





  
  
  
    
  
  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_huc473e5d783e956425af2298567207379_1878707_250x250_fill_q90_lanczos_center.jpeg" itemprop="image" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="/">Katherine Hoffman</a></h5>
      <h6 class="card-subtitle">Research Biostatistician</h6>
      <p class="card-text" itemprop="description">I am passionate about meaningful, reproducible medical research.</p>
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
          <li>
            <a itemprop="sameAs" href="mailto:kathoffman.stats@gmail.com" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://twitter.com/rkatlady" target="_blank" rel="noopener">
              <i class="fab fa-twitter"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://github.com/hoffmakl" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>



      
      
      <div class="article-widget">
        <div class="hr-light"></div>
        <h3>Related</h3>
        <ul>
          
          <li><a href="/blog/iterated-expectations/iterated-expectations/">Understanding Conditional and Iterated Expectations with a Linear Regression Model</a></li>
          
          <li><a href="/blog/ditl-biostats/">A Day in the Life of a Biostatistician</a></li>
          
          <li><a href="/blog/sl/superlearning/">Become a Superlearner! An Illustrated Guide to Superlearning</a></li>
          
          <li><a href="/blog/collider-bias/hardest_part_of_causal/">The Key to Learning Causal Inference</a></li>
          
          <li><a href="/blog/covid/covid-functions/">My favorite lines of data wrangling code during the NYC COVID-19 outbreak</a></li>
          
        </ul>
      </div>
      
    

    

    


  </div>
</article>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.16bbb3750feb7244c9bc409a5a4fe678.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms</a>
        
  </p>
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
