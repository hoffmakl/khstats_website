[{"authors":["admin"],"categories":null,"content":"I am a Research Biostatistician at Weill Cornell Medicine in New York City who is passionate about meaningful, reproducible medical research. In addition to my research collaborations, I assist with multiple courses in WCM’s Biostatistics and Data Science MS program.\nOutside of work I like to read, play sports, and travel. Prior to becoming a statistician, I cared for patients in the hospital as a nurse tech, played collegiate softball and coached high schoolers, and wrote a thesis on artists’ portrayal of mental illness.\n","date":1441065600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1441065600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Research Biostatistician at Weill Cornell Medicine in New York City who is passionate about meaningful, reproducible medical research. In addition to my research collaborations, I assist with multiple courses in WCM’s Biostatistics and Data Science MS program.\nOutside of work I like to read, play sports, and travel. Prior to becoming a statistician, I cared for patients in the hospital as a nurse tech, played collegiate softball and coached high schoolers, and wrote a thesis on artists’ portrayal of mental illness.","tags":null,"title":"Katherine Hoffman","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":["blog"],"content":" Earlier this year I wrote my first blog post, “A Day in the Life of a Biostatistician”, documenting the granular details of my work as an early career academic research biostatistician. I’m excited to announce I am turning that post into a “day in the life” series in which I interview other biostatisticians with differing roles. My hope is that it will enlighten anyone interested in the field of biostatistics, and especially help undergraduate and current biostatistics Masters students make informed decisions about their careers.\nMy first interviewee is Kim Hirschhorn, a former classmate and good friend from my time at the University of Michigan School of Public Health. Kim is an avid reality TV show watcher, loves Eggo waffles and Hostess Ho-Hos, and is a great statistician; so great, professors were often confused as to why she wasn’t planning to pursue a PhD. Kim, however, has always been adamant that she doesn’t need a PhD to have the career she wants.\nKim’s determination to find a job which allowed for ample career growth with “only” an MS in Biostatistics paid off. After graduating in 2018, she chose to work as a biostatistician at PRA Health Sciences, a Contract Research Organization (CRO) for pharmaceutical companies. Biostatistician roles at CROs offer excellent career trajectory for Masters-level statisticians and don’t have a job title ceiling as some careers in statistics notoriously do for those without a PhD. Additionally, it’s a lucrative job option for a Masters-level biostatistician. (🤑!) For more information on salaries of early career statisticians you can check out the American Statistical Association’s recent survey of 2018 Masters in Statistics graduates. But, to learn more about what Kim actually does as a biostatistician at a pharmaceutical CRO, read on!\nKat: Thanks for taking the time to chat, Kim! Can you tell me where you work and what the mission of your company is?\nKim: I work at the Chicago office of a large CRO called PRA Health Sciences. PRA stands for Pharmaceutical Research Associates, and our primary responsibility is to run clinical trials for pharmaceutical companies. This includes everything from planning the study at an administrative level – such as identifying physicians to recruit patients and administer drug therapies – to collecting data like patients’ disease progression and adverse events, analyzing and summarizing the results, and submitting requests for the successful trials to be approved by the Food and Drug Administration (FDA). After a pharmaceutical company has researched and developed a potential new drug, we partner with them to implement the various phases of clinical trials necessary to test that drug.\nWhoa, sometimes I forget about all the steps in a clinical trial. Before we go any further, can you give us a quick explanation about what those phases of clinical trials mean?\nThere are three main phases: Phase I, II, and III. In general, Phase I clinical trials check whether a drug is safe to administer. Sometimes this also involves testing which dosage of a drug is safe – or at least not overwhelmingly toxic – to the body. Phase I trials are usually done on a small group of patients. Phase II trials are done on a larger group of patients and focus on whether the drug is effective, or in other words, whether it can actually fix whatever health problem the pharmaceutical company had in mind when developing it. Most drugs fail in Phase II.\nIf a drug does move onto a Phase III trial, its performance in comparison to the current standard of care (which is often another drug on the market) is evaluated. In both Phase II and III, patients are randomized into treatment and control groups and typically neither physicians nor patients know which treatment is administered. Even patients who are not receiving a treatment will receive a sugar pill, or placebo drug. Oftentimes a clinical trial’s aims will fall somewhere between two phases, for example, I’ve worked on Phase 1b/2a trials that collect information on safety, determine the recommended dose, and then evaluate the drug’s efficacy.\nI see, so which of those phases do you work on?\nI have been a Biostatistician I for a bit over a year now, so that means I am the lead biostatistician on a few simple Phase I trials. There is usually not much statistical testing occurring here; it’s all about how many patients have an adverse response to the drug. Since I am still in the most junior biostatistician role, a lot of my time is spent doing biostatistical support for Phase II and III trials, where more senior biostatisticians oversee my work and pre-specify the analyses. The longer I stay at my job, the more responsibilities I will have and the more complex studies I will lead.\nWhat’s involved in leading a study, even a “small and simple” phase I? How is that different from the work you do as “biostatistical support” on the Phase II and III trials?\nWhen I am the lead of a study, I am meeting with members of the pharmaceutical company and working with them to develop a statistical analysis plan. Once the clinical trial starts and I begin to receive data, I work with programmers to ensure everything that needs to be done for the analysis is completed in the time allotted by that trial’s budget. Since the studies I am leading now are early phase, I am in charge of doing all the statistical analyses and reporting the results back to the pharmaceutical company. \nIn contrast, when I am biostatistical support, I am mostly executing analyses already specified in a statistical analysis plan. This typically involves writing macros in the statistical programming language SAS to ultimately produce what is dozens of outputs. A large portion of my time as a junior biostatistician is spent figuring out the best way to present that huge amount of data and results in a comprehensible way. Even before I have data from a clinical trial, I have to plan out detailed tables and prepare a shell document for when the data is ready for analysis.\nWho are you working with in your day-to-day roles?\nI get assignments from my manager, and then work with the lead biostatisticians on each trial. It is standard in the pharmaceutical industry that all analyses must be independently reproduced. This usually means the lead biostatistician is redoing my analysis without looking at my code, so sometimes I have to work closely with him or her to figure out why our results are not matching. Besides that, I frequently collaborate with the data programmers and statistical programmers in charge of the data for the trials I am working on.\nData programmers are in charge of taking raw data from the trials, checking it for inconsistencies, and putting it into a standardized form for statistical programmers. Statistical programmers then take those standardized data sets, derive many new variables from those initially collected for each patient, and produce hundreds of tables and figures summarizing the data. In some cases they also help prepare the data for my analyses, for example, they might write code to calculate the number of days or months until each patient experienced disease progression so that I can use that information for statistical models.\nIf there is a problem with the data when I am running a model, I ask the statistical programmer to check his or her code, and if there is no issue there, the data programmer looks at their code. If necessary, the data programmer may go back to the clinical sites who are collecting the data from patients and ask them to correct any missing information or inconsistencies.\nSounds like your data is in pretty good shape when it arrives to you, then! Earlier you mentioned writing macros in SAS. Does everyone use SAS? Could you use R or another programming language if you wanted?\nI have used R for a few side analyses, such as a data mining analysis. However, the industry standard for pharmaceuticals has always been SAS. I don’t foresee that changing anytime soon. Although a huge benefit of R is that it is free and open source software, meaning anyone can contribute code in a package, SAS has the advantage that if you run a certain type of statistical model, you can be absolutely sure that is what ran on your data. Because SAS is a paid software, it is liable for what it says it is doing, and there is always support on hand if you have questions about errors or results you are getting from any given data procedure.\nWhat are your hours like? What sort of flexibility do you have for vacation, or working remotely?\nI usually get in at 8:15 and leave somewhere between 4:45 and 5:15. I do get a lot of vacation days, with the caveat that if there is a deliverable deadline for a project I’m working on, I may not be able to take my vacation during that time. As for working remotely, it’s an option I have as-needed, such as if I have a doctor’s appointment. The job can definitely be done 100% remotely, and in fact many members of the company work remotely, but it’s not really an option for a Biostatistician I to do all the time because we rely so heavily on our senior biostatisticians. I prefer that, though - it’s easier for me to work in the office!\nHow will your roles and responsibilities change as you progress as a biostatistician at a CRO?\nWhen I said a lot of my time is spent working on table shells and report planning, I think it’s worth acknowledging that that is not a very exciting activity. However, as a Biostatistician I progresses to Biostatistician II, Senior Biostatistician, Principal Biostatistician, Senior Principal Biostatistician, etc., a lot of those more mundane (in my opinion) tasks decrease. You are in charge of much more complex studies and specifying the statistical analyses for that clinical trial. The work also naturally becomes more managerial.\n-- -- Being in charge of a trial means meeting with both external clients and internal company leadership, setting timelines for data/statistical programmers and junior biostatisticians, answering questions that come up about data and analyses, maintaining oversight of the hours each team member is spending on the project, and tracking the corresponding budget carefully. As biostatisticians progress in the career ladder at a CRO, they have some flexibility in how much data they actually analyze on a day-to-day basis.\nWhat made you decide to take this position at a CRO over your other offers?\nWell of course it’s not all about money, but this was one of the highest offers I received, so that helped. The potential for career growth was also very appealing to me. Typically after about 4-5 years you are a Senior Biostatistician and qualified to lead any study. But, you can lead studies long before this if the pharmaceutical company agrees you are qualified to do so. I really like that career progression at a pharmaceutical CRO is very much about experience and skills, as opposed to whether or not you hold a PhD. This is often not the case if you work directly for a pharmaceutical company.\nFinally, what made you choose to enter the field of Biostatistics?\nI have always been drawn to a career in public health. During my first year at the University of Illinois, I was a stereotypical freshman pre-med student. I ultimately changed my mind about medical school and got a Bachelor’s degree in statistics, but I still took several epidemiology and biology classes just because I found them interesting. Math has always been my strongest subject, but I wanted to find a way to combine it with my other interests. After doing a fair share of Googling, I found the field of Biostatistics. I met with the head of U of I’s Statistics MS program, and he shared his experience of working in industry as a biostatistician before becoming a professor. He spoke very highly of the field and gave me a lot of great information on the types of careers I could have with a Masters in Statistics or Biostatistics. I was pretty much sold after that meeting.\nLooking back, are you happy with your decision to do a Masters in Biostatistics, rather than Statistics or Applied Statistics?\nYes, I’m really happy I decided on a Masters in Biostatistics. Throughout my program, our applied problem sets were always related to medicine or healthcare in some way, and it was easy for me to take health-specific statistics classes, such as a clinical trials methodology course. Since I was pretty sure I wanted to go into healthcare, I think biostatistics was a great decision for me, because a Masters in Biostatistics shows my passion for the field and may give me an edge over similar applicants who have a more general Masters in Statistics or Applied Statistics. I still find public health to be the most interesting sector to practice statistics in, so I think the degree will always be to my advantage.\nThanks so much for chatting, Kim!\nIf you have other questions for Kim, or if there are careers within biostatistics you’d like to hear about, feel free to email me and let me know.\nAll the best,\nKat\n","date":1570414394,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570414394,"objectID":"6d6004832d3eb0a19c66c9e1ba411278","permalink":"/blog/ditl_kim/ditl_kim/","publishdate":"2019-10-06T21:13:14-05:00","relpermalink":"/blog/ditl_kim/ditl_kim/","section":"blog","summary":"Earlier this year I wrote my first blog post, “A Day in the Life of a Biostatistician”, documenting the granular details of my work as an early career academic research biostatistician. I’m excited to announce I am turning that post into a “day in the life” series in which I interview other biostatisticians with differing roles. My hope is that it will enlighten anyone interested in the field of biostatistics, and especially help undergraduate and current biostatistics Masters students make informed decisions about their careers.","tags":["career","biostatistics","interview","SAS"],"title":"Stats on Drugs An interview with a Pharmaceutical CRO Biostatistician","type":"blog"},{"authors":[],"categories":null,"content":"","date":1568142000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568142000,"objectID":"87c5663bad4f0785e9c8b5d0499cc05f","permalink":"/talk/superlearner/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/superlearner/","section":"talk","summary":"Using sl3 to build ensemble learning models in R","tags":["R"],"title":"Become a Superlearner","type":"talk"},{"authors":[],"categories":null,"content":"","date":1565699400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565699400,"objectID":"6e466ea94f65a8e738c2628e94388dac","permalink":"/talk/power-sims/","publishdate":"2019-08-13T19:00:00Z","relpermalink":"/talk/power-sims/","section":"talk","summary":"An introduction to coding power simulations in R","tags":["R"],"title":"Power Simulations in R","type":"talk"},{"authors":[],"categories":null,"content":"","date":1564480800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564480800,"objectID":"c5b5fbc24d34f2c1aab937c60d6910cb","permalink":"/talk/digoxin/","publishdate":"2019-06-17T19:00:00Z","relpermalink":"/talk/digoxin/","section":"talk","summary":"ASA Joint Statistical Meeting 2019","tags":[],"title":"Estimating the Causal Effect of Digoxin using Marginal Structural Models","type":"talk"},{"authors":[],"categories":null,"content":"","date":1560798000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560798000,"objectID":"29a9a403620ac1977575ef42a1d516eb","permalink":"/talk/lightning-talk/","publishdate":"2019-06-17T19:00:00Z","relpermalink":"/talk/lightning-talk/","section":"talk","summary":"R Projects and here::here()","tags":["R"],"title":"Fireproof Your Computer from Jenny Bryan","type":"talk"},{"authors":null,"categories":["blog"],"content":" In early May I attended the New York R Conference. There were 24 speakers, including my coworker at Weill Cornell Medicine, Elizabeth Sweeney! Each person did a 20-minute presentation on some way they use R for their work and/or hobbies. There was a ton of information, and even though not all of it was directly useful for my workflow as a statistical consultant in an academic setting, I really enjoyed being around so many people who love R.\nI’ve linked some videos of my favorite talks and put together some the topics/packages/functions I found most intriguing or useful in my day-to-day work as a research biostatistician. (This was originally a presentation for my biostatistics team’s computing club.)\nVisualizing data with naniar Brooke Watson, a data scientist at the American Civil Liberties Union, gave a great presentation on how she uses R to defend immigrants. She shared several data wrangling tips. One new function for me was naniar::vis_miss() to visualize your missing data quickly.\n#install.packages(\u0026quot;tidyverse\u0026quot;) #install.packages(\u0026quot;naniar\u0026quot;) library(tidyverse) library(naniar) vis_miss(airquality) # a base R data set It returns a ggplot2 object so you can edit titles, colors, etc. if necessary. You can also add various sorting and clustering arguments to make it easier to see patterns of missingness in your data.\n Checking out data differences with daff Brooke also gave a demo for a neat package to check if and where differences in two data sets are occurring.\n#install.packages(\u0026quot;daff) library(daff) dat1 \u0026lt;- data.frame(A = c(1:3), B = c(T,F,T)) dat2 \u0026lt;- data.frame(A = c(1:4), C = c(\u0026quot;apple\u0026quot;,NA,NA,\u0026quot;banana\u0026quot;)) my_diff \u0026lt;- diff_data(dat1, dat2) my_diff ## Daff Comparison: \u0026#39;dat1\u0026#39; vs. \u0026#39;dat2\u0026#39; ## +++ --- ## @@ A C B ## + 1 apple TRUE ## 2 \u0026lt;NA\u0026gt; FALSE ## 3 \u0026lt;NA\u0026gt; TRUE ## +++ 4 banana \u0026lt;NA\u0026gt; -- I thought this would be useful for when you receive new data sets and want to make sure column names, patients, etc. haven’t changed. Check out the full documentation here.\n Gohelverse Noam Ross shared code for editable figures using David Gohel’s officer and rvg packages. I shared some example code for my team on github after I saw him present it at an R-Ladies event in the fall. Essentially you can run some pretty simple lines of code to output figures (base R, ggplot2, or otherwise) as editable figures in Powerpoint. Noam reminded us that whoever you give these figures to will now be able to edit anything, even data points, so keep that in mind before you freely give away editable figures… :)\n#install.packages(\u0026quot;rvg\u0026quot;) #install.packages(\u0026quot;officer\u0026quot;) library(rvg) library(officer) #sample data dat \u0026lt;- data.frame(x = rnorm(100, 10), y = rnorm(100, 100), z = rnorm(100, 1)) #make an empty ppt read_pptx() %\u0026gt;% #add a slide, must specify the slide layout and layout name add_slide(layout=\u0026quot;Title and Content\u0026quot;, master=\u0026quot;Office Theme\u0026quot;) %\u0026gt;% #specify what you want on the slide (code = ...) #type=\u0026quot;body\u0026quot; means the plots going in the body part of the layout #width and height are in inches ph_with_vg(code = plot(dat$x, dat$y, main=\u0026quot;Edit me!\u0026quot;, pch=16), type=\u0026quot;body\u0026quot;, width=6, height=4) %\u0026gt;% #output your ppt (target argument is just the file destination/name) print(target=\u0026quot;plot.pptx\u0026quot;) ## [1] \u0026quot;/Users/katherinehoffman/Desktop/basic/content/blog/nyrconf/plot.pptx\u0026quot;  Going from RMarkdown to Word, and back again with redoc Noam also shared his new package, redoc, which allows you to reload an Rmd-generated word file back into R as a modified Rmd file.\nThis is part of his goal to decrease the pain of “the valley of heartbreak.” Installation command is:\n#remotes::install_github(\u0026quot;noamross/redoc\u0026quot;) You may need to update several packages to get it to run correctly, but after that the main commands are just redoc and dedoc. To see for yourself, try running my github code, making some changes to your word doc, and reloading back into Rmarkdown with the dedoc() function.\n Pipelines in drake This could definitely be an entire computing club presentation… but for long projects that you have to redo with new data often, drake is becoming really popular. Amanda Dobbyn gave an awesome presentation and you can see her slides here.\nA super informative bookdown guide by the authors can be found here. Essentially their motto is “what gets done stays done” so that you are not redoing work you’ve already done in order to update your results. Yet, you’re still redoing what needs to be done in a reproducible way!\n Git merge conflicts I went to a whole-day workshop on Git so if you’re interested in talking more about this let me know. BUT the biggest thing I learned was that if you are ever using Git and find your code has strange characters like \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; HEAD followed by ======== and a long set of letters/numbers, this means you have a merge conflict. It’s meant to be a flag so you know where to fix the differences in your two files you’re trying to version control! I spent days struggling with this problem before, so I thought I’d pass the message along in case anyone runs into it someday. :)\n Talks to check out Some of my favorite talks from the conference were…\n Emily Robinson’s accessible instructions for how to make a package with usethis\n Jaqueline Nolis’ really funny talk on how neural nets aren’t actually hard at all\n Andrew Gelman’s discussion on “solving all your statistical problems with p-values” (but he’s a Bayesian, ha ha)\n   A bonus! This was not from the New York R Conference but I saw it on Twitter while making this presentation for my computing club and I really enjoyed it…\n#install.packages(\u0026quot;genius\u0026quot;) library(genius) genius_lyrics(\u0026quot;the beatles\u0026quot;, \u0026quot;hey jude\u0026quot;) ## # A tibble: 53 x 3 ## track_title line lyric ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 Hey Jude 1 Hey Jude, don\u0026#39;t make it bad ## 2 Hey Jude 2 Take a sad song and make it better ## 3 Hey Jude 3 Remember to let her into your heart ## 4 Hey Jude 4 Then you can start to make it better ## 5 Hey Jude 5 Hey Jude, don\u0026#39;t be afraid ## 6 Hey Jude 6 You were made to go out and get her ## 7 Hey Jude 7 The minute you let her under your skin ## 8 Hey Jude 8 Then you begin to make it better ## 9 Hey Jude 9 And anytime you feel the pain, hey Jude, refrain ## 10 Hey Jude 10 Don\u0026#39;t carry the world upon your shoulders ## # … with 43 more rows  Takeaways  You can check out tweets from the conference by searching the hashtag #rstatsnyc on Twitter\n Check out the R-Ladies NYC meetups and New York R meetups!\n   ","date":1559441594,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559441594,"objectID":"f885156b007396c5055ed0954f9a5d55","permalink":"/blog/nyrconf/nyr-conf-2019/","publishdate":"2019-06-01T21:13:14-05:00","relpermalink":"/blog/nyrconf/nyr-conf-2019/","section":"blog","summary":"In early May I attended the New York R Conference. There were 24 speakers, including my coworker at Weill Cornell Medicine, Elizabeth Sweeney! Each person did a 20-minute presentation on some way they use R for their work and/or hobbies. There was a ton of information, and even though not all of it was directly useful for my workflow as a statistical consultant in an academic setting, I really enjoyed being around so many people who love R.","tags":["R Markdown","New York R Conference","rstats","rstatsnyc"],"title":"Tips and Tricks from the New York R Conference","type":"blog"},{"authors":null,"categories":["blog"],"content":" It seems fitting that my first blog post is on a topic that I tried and failed to find via Google search a few years ago.\nI’ll back up for a second. A few years ago I was a recent college graduate, and trying hard to “figure out my life.” My major was biochemistry, which is one of those degrees where 99%* of people just keep on going to school.\nI was working full-time night-shift at a hospital as a patient care technician. The key word in that sentence is “night-shift” which meant that even on my days off, I didn’t sleep at night, but all my friends and family did. So, I was often alone and awake, with a lot of time to think about my future… and surf the web for potential careers.\nI knew I wanted a job in healthcare, but I was confused as to where in medicine would be a good fit for me. I could visualize very clearly what my days at work would look like if I were to become a physician, or a physician assistant, or a registered nurse (all careers I developed lengthy pros and cons lists for).\nHowever, there was another career involving medicine that I was drawn to but didn’t know enough about. “Biostatistics” was a class biochemistry majors took at my university, but I had been exempted because I took AP Statistics in high school.\nTo me, biostatistics seemed to be the application of some high school-level math to biological problems. I had no concept of what a degree in biostatistics, and much less a career as a biostatistician, could entail. Endless Google searches with some variant of “what does a biostatistician do” and even “day in the life of a biostatistician” had not given me a very good picture of what I would actually be doing as a biostatistician.\nI ultimately lucked out during a conversation with a professor during my senior year of college. I was rambling about my many life plans and he mentioned his cousin was the chair of a well-known Biostatistics program. He encouraged me to email her my questions about biostatistics, and I am so grateful she took time to respond with detailed answers. Her description of life as a biostatistician was enough for me to choose going to graduate school for an MS in biostatistics over medical school/physician assistant school/second-degree nursing.\nI feel wholeheartedly that although I would have enjoyed my life as an MD/PA/RN, biostatistics is the right career for me. So, in honor of my confused younger self, and as a way of paying it forward, I’ve dedicated this topic for my very first blog post!\nA full disclaimer - what follows is a day in the life of one masters-level, academic research-focused biostatistician and I cannot make claims about the careers of statisticians in industry or pharmaceuticals or hospitals or government. In addition, here’s a bit more background before I get into the granular details of my work:\nMy official job description is to assist investigators (i.e. physicians or PhD-level researchers with a scientific question) throughout all stages of the scientific research process. This means helping with study design, data collection, data cleaning (also known as getting the data in the right form for analysis and making sure nothing is obviously incorrect), data visualization, statistical analysis, reporting and explaining my results, and writing methods and results sections for scientific papers. You will soon see that on any given day I am working on multiple projects at various stages of this process.\n I will mention R/Rstudio a bit. For those who are not familiar with it, R is an open-source (which means anyone can help contribute) programming language that is well-equipped for statistical analysis. It’s arguably very similar to Python, which is a more widely used language, but statisticians tend to use R more because its statistical packages are very well-developed. During grad school I used Python because I worked in a computational biology lab, and I learned SAS (another statistical programming language) in some of my classes, but R is what I prefer these days. Rstudio is a platform that makes it more user friendly to use R.\n  So, without further ado! An average day**:\n9:30AM - I arrive at my office and spend a few minutes chatting with my coworkers. To set the scene for you, I have a fairly spacious cubicle within a group of five other cubicles. I sit next to another research biostatistician, two health informatics professionals, and two clinical trial grant specialists. I’m actually not completely sure what that last pair’s title is, but I know their primary task is to make sure several multi-million dollar clinical trial grants stay funded (woah). Everyone I sit by is young and goofy, but very driven, making for a fun office environment.\n9:45AM - I check and answer new emails from researchers I collaborate on projects with. I send my availability for a meeting to a group of doctors who want to go over the results of a recent analysis I did on Body Mass Index and death rates in the Intensive Care Unit. In a different thread of emails, I thank several researchers from another university for clarifying their methods and sending me code for an analysis similar to one I will soon work on.\n10:00AM - I open a manuscript draft for a paper I received yesterday. It’s from a group of residents and medical students I worked with a few months ago. Their study looks at the association between blood levels of a certain biomarker and the time to death in cancer patients. My role in the analysis was to examine the associations between several biomarkers such as phosphorus, phosphate, and calcitriol. I then fit a regression model, just like y=mx+b, but with way more math. For this analysis I used a model for when your y is a time to an event (death, in this case), fittingly called a survival model. After adjusting for confounding factors like age, which affects both tumor progression and biomarker levels, there was a significant association between the biomarker and time to death in cancer patients.\nThe researchers have asked for my assistance in writing the methods section. The methods section of a scientific article is the steps the scientists took to analyze data explicitly written out for anyone looking to review or learn about their work. I read through their current draft of the paper carefully, make some edits, and send it back. They are hoping to submit this paper to a peer-reviewed journal within a few weeks.\n10:45AM - I have a weekly meeting a few blocks from my office with a neurologist I spend a large portion of my time working with. She is a leader in the field of Alzheimer’s research, and I find it very rewarding to work on her data and be a small part of a growing body of research in the field. I am “contracted” out to her research as I am to all of the researchers I work with—it’s how my institution budgets funding for grants. One of the faculty-level biostatisticians in my department—which means he has a PhD and specializes in certain statistical methods—is also part of this contract, and some days, like today, he joins me at these meetings.\n11:00AM - This week’s meeting is pretty straightforward. We discuss how we can improve one of the neurologist’s National Institute of Health grants from a statistics standpoint. The statistical methods for this project can get complicated, in part because we are looking at the brain scans of women in different stages of menopause over time, and we have to consider age as a confounding factor. We want to convey to the reviewers of our grant how we plan to do this. Since this is a methods-focused meeting, I mostly listen and take notes along with two neurology research coordinators that also attend these weekly meetings. When the meeting concludes I have for less work than usual - I only need to make a few graphs representing our study design and past results for inclusion to the grant.\n12:00PM - I head to lunch with a group of coworkers. They have gotten food from a nearby salad place, and we sit in one of our favorite buildings on campus and eat together. Our jokes oscillate from incredibly nerdy to pretty stupid. One of my coworkers points out that our hair is styled the same way for the third day in a row.\n12:45PM - I get back to my desk and type up my handwritten notes from the neurology meeting and put them in that project’s “Notes” folder. It’s important to me that I keep track of all my meetings electronically - I fear losing my notebooks or someone else having to decipher my cursive should I ever have to pass off a project.\n1:00PM - I start to make a plan for a different analysis I’m working on. This project is something new for me - it involves a protein assay and data for 1000+ different protein expression levels. The researcher I’m working with wants to know which proteins are over- and under-expressed in people with a specific autoimmune disorder and a certain type of lung disease. I’ve recently spoken to some bioinformaticians and have a clearer idea of the analysis I need to do. I draw out a little map of the code organization I think would be the most efficient for this analysis and open up Rstudio.\n1:30PM - I get to work writing up functions, which is just a fancy programming way of saying your code can do the same thing to multiple data sets (or subsets of patients, as is the case of this protein expression study I’m doing). Sometimes it takes a bit longer to write my functions than it would if I were to just copy and paste my code several different times, but the final code is much more readable and less prone to errors. By the time I’m done working, I have some interactive plots showing the significant and non-significant results. When you hover over them, they show what protein corresponds to which point on the graph. They look like this, except this is not the real data we used in her study.\nI use Rstudio and its amazing Rmarkdown tool to craft a draft report to the researcher, and I save it with today’s date in my “Reports” folder for that project. The report so far includes unadjusted and adjusted models of all the protein expressions using very small p-values to account for the 1000+ statistical comparisons we’re making. I show the results in various plots such as the one above (called a “volcano plot” for its shape).\nI have also started writing code for models to determine which proteins are most different, or uniquely expressed, between subgroups of patients. Tomorrow, I will use a technique common in machine learning, called clustering, to see if these protein expressions can correctly classify subgroups of patients. The goal is to find a minimum group of proteins to identify patients of interest who have both the autoimmune disorder and the lung disease my collaborator is interested in. One way this research could be impactful is that it may help determine which proteins pharmaceuticals should develop drugs to target.\nI close the report; I will continue working on this analysis tomorrow.\n4:45PM - It’s time for my last meeting of the day. I head to another floor of my office building and get my laptop set up in a conference room. I await the arrival of several doctors. It will be my first time meeting most of them, and our task today is to discuss the data collection process for a future study involving both genetic mutation data from tumor biopsies and clinical data from electronic health records on thousands of patients with lung cancer.\n5:00PM - The doctors arrive and, after introductions, we talk about the current stage of the project and what the goals are. We discuss the timing of starting chart reviews of patients, how we will upload the information to a database efficiently, and what might be the best way to condense the highly detailed genetics data into useful information for an analysis. Our solution will likely involve a series of iterative searches through the columns containing genetic information.\n6:00PM - The meeting ends, and I go back to my desk to record more handwritten notes. I log the hours I spent on each project that day into Toggl, which is the time-tracking application our team uses. This is so we know how much time we’re spending on each project, and is as much for our own sake as it is anyone else’s. I update my to-do list, which is a giant color-coded excel spreadsheet, and eat a few chocolate covered raisins as my reward for a productive day.\n6:30PM - I leave work! I typically have some kind of activity, like happy hour (see my cute cubicle buddies below), a sports game, or Spanish class that I’m heading off to. Some days I attend coding workshops hosted by groups such as R-ladies. On nights when I’m feeling especially nerdy, I’ll go home and read a statistics paper or sift through the #rstats tips on twitter.\n…So, there you have it. One average daily experience as an early career masters-level statistician. All in all, I have a fantastic work-life balance and overall work environment. Every day I get to learn more about science, medicine, statistics, and the intersection of these wonderful ideas. Although it varies quite a bit, approximately 10% of each day involves writing, 20% interacting with other researchers, and the rest of it is spent thinking critically and finding answers to problems I am passionate about.\nI hope if there are any 22, 42, or 14 year-olds out there considering a career in biostatistics and struggling to figure out what on earth we actually do, that you find this post and it lessens your confusion! Feel free to reach out to me if you have questions.\nAll the best,\nKat\n*Not a real statistic.\n**Exact details and diseases of the studies I am currently working on have been generalized or altered to protect the research interests of my collaborators.\n","date":1555467194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555467194,"objectID":"1e3d422df973b62b5dd164452fa08eb5","permalink":"/blog/ditl-biostats/","publishdate":"2019-04-16T21:13:14-05:00","relpermalink":"/blog/ditl-biostats/","section":"blog","summary":"It seems fitting that my first blog post is on a topic that I tried and failed to find via Google search a few years ago.\nI’ll back up for a second. A few years ago I was a recent college graduate, and trying hard to “figure out my life.” My major was biochemistry, which is one of those degrees where 99%* of people just keep on going to school.","tags":["biostatistician","career","rstats","SAS","R","STEM","statistics"],"title":"A Day in the Life of a Biostatistician","type":"blog"},{"authors":null,"categories":["Rmarkdown"],"content":"  When doing long, identical analyses on different data sets or variables, it can be useful to have one function which outputs your analyses in an Rmarkdown friendly (ie., with headers) format.  This is a simple example of how multiple mini-analyses can be combined into one run-all function containing headers.  Let’s say we have two separate data sets, dat1 and dat2, and we want to look do two analyses on each data set.  Look at the distribution of each x and y variable   Run and report a regression model, y ~ x    We want whoever is receiving our report to be able to click on each sub-analysis in our table of contents.  Let’s start by setting up our Rmd chunks, loading our libraries, and creating our data sets: knitr::opts_chunk$set(echo=T, results=\u0026quot;asis\u0026quot;, warning=F, message=F) library(tidyverse) set.seed(7) dat1 \u0026lt;- data.frame(x=rnorm(50),y=rnorm(50)) dat2 \u0026lt;- data.frame(x=rnorm(500),y=rnorm(500))  We can then make a few mini functions which will carry out each analysis. xDistFun \u0026lt;- function(dat){ ggplot(dat, aes(x)) + geom_histogram(fill=\u0026quot;blue\u0026quot;)} yDistFun \u0026lt;- function(dat){ ggplot(dat, aes(y)) + geom_histogram(fill=\u0026quot;red\u0026quot;)} xRegFun \u0026lt;- function(dat){ lm(y ~ x, data=dat) %\u0026gt;% broom::tidy() %\u0026gt;% knitr::kable()}  Finally, we’ll organize these mini functions into one function which will run all our analyses and nicely organize them into Rmarkdown friendly output.  Writing a function to return this output is non-intuitive, because it requires your tables and figures to be printed as-is, while your headers must to be converted to html script. This is achieved with the command cat() and a for loop.  Note: you cannot save the cat-ed version of your header, or cat it at all until you have reached the end of your function and you are ready to return/print all of your results. This is because cat immediately returns its output to the screen (and also does not save as an object). runManyFuns \u0026lt;- function(dat){ # grab the name of our object for the main header title \u0026lt;- deparse(substitute(dat)) # Name of our first subheader h1 \u0026lt;- \u0026quot;Distributions\u0026quot; # list of two mini-analyses under subheader #1 out1 \u0026lt;- list(xDistFun(dat = dat), yDistFun(dat = dat)) # second subheader h2 \u0026lt;- \u0026quot;Regression Model\u0026quot; # second analysis out2 \u0026lt;- xRegFun(dat = dat) # combine headers into one vector headers \u0026lt;- c(h1, h2) # combine all output into a list to parse thru out \u0026lt;- list(out1, out2) # makes our title header cat(paste0(\u0026quot;\\n#Data: \u0026quot;, title, \u0026quot;\\n\u0026quot;)) for (i in 1:length(headers)){ # parse through each element of our subheader vector cat(paste0(\u0026quot;\\n##\u0026quot;, headers[i], \u0026quot;\\n\u0026quot;)) # print each element of our output list print(out[i]) } }  This new function allows us to run and report our identical analyses on both dat1 and dat2 in a clean and concise way.  I have not yet figured out how to get rid of the [[1]] numbers signifying the elements of my list. I hope to utilize the htmltools package to get rid of these eventually. # Run same analysis on different data sets, outcomes, etc. runManyFuns(dat1)  Data: dat1   Distributions   [[1]][[1]][[1]] [[1]][[2]]   Regression Model   [[1]]   term  estimate  std.error  statistic  p.value     (Intercept)  0.0602311  0.1322251  0.4555193  0.6507897   x  -0.0902709  0.1287207  -0.7012929  0.4865065     runManyFuns(dat2)    Data: dat2   Distributions   [[1]][[1]][[1]] [[1]][[2]]   Regression Model   [[1]]   term  estimate  std.error  statistic  p.value     (Intercept)  -0.0648102  0.0428622  -1.5120607  0.1311527   x  0.0376818  0.0424069  0.8885765  0.3746597         // add bootstrap table styles to pandoc tables function bootstrapStylePandocTables() { $(‘tr.header’).parent(‘thead’).parent(‘table’).addClass(‘table table-condensed’); } $(document).ready(function () { bootstrapStylePandocTables(); });\n","date":1555372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555372800,"objectID":"05fc19ab1bbeaac53e39bcb3212f3117","permalink":"/tutorial/headers/headers-in-functions/","publishdate":"2019-04-16T00:00:00Z","relpermalink":"/tutorial/headers/headers-in-functions/","section":"tutorial","summary":"When doing long, identical analyses on different data sets or variables, it can be useful to have one function which outputs your analyses in an Rmarkdown friendly (ie., with headers) format.  This is a simple example of how multiple mini-analyses can be combined into one run-all function containing headers.  Let’s say we have two separate data sets, dat1 and dat2, and we want to look do two analyses on each data set.","tags":["R","Rmarkdown","headers in functions"],"title":"Outputting Rmarkdown Headers within Functions","type":"tutorial"},{"authors":null,"categories":["R"],"content":"  A Presentation for Weill Cornell Medicine’s Biostatistics Computing Club Image courtesy of Allison Horst’s Twitter: @allison_horst\n Introduction Why dplyr?  Powerful but efficient\n Consistent syntax\n Fast\n  Function chaining\n Works well with entire tidyverse suite   Efficiency*\n Simple syntax\n Function chaining\n Ability to analyze external databases\n Works well with other packages in tidyverse suite ggplot2 tidyr stringr forcats purrr   *if you start dealing with data sets with \u0026gt; 1 million rows, data.table will be much faster\ndata(\u0026quot;iris\u0026quot;) library(tidyverse) ## ── Attaching packages ── tidyverse 1.2.1 ── ## ✔ ggplot2 3.2.1 ✔ purrr 0.3.2 ## ✔ tibble 2.1.3 ✔ dplyr 0.8.3 ## ✔ tidyr 0.8.3 ✔ stringr 1.4.0 ## ✔ readr 1.3.1 ✔ forcats 0.4.0 ## ── Conflicts ───── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag()  Tibbles  An “update” to the data.frame object class in R\n Updates relevant for using dplyr:\n Vectors of length 1 are automatically recycled\n Newly created vectors can be referenced in the same line of code\n  Other perks: only the first 10 lines print to the screen so your console doesn’t get overloaded\n Read more about tibbles here: https://r4ds.had.co.nz/tibbles.html\n dplyr automatically converts objects to tbl_df (tibble data frame) objects\n   Piping  %\u0026gt;% operator from library(magitrr)\n Use %\u0026gt;% to send an object (typically a dataframe) to the next function\n The function you pipe to will use the object in front of the %\u0026gt;% as its first argument\n  iris %\u0026gt;% head() # equivalent to head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa iris %\u0026gt;% head(n=3) # equivalent to head(iris, n=3) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa  If you don’t want it to be the first argument, use .  iris %\u0026gt;% lm(Sepal.Width ~ Sepal.Length, data=.) ## ## Call: ## lm(formula = Sepal.Width ~ Sepal.Length, data = .) ## ## Coefficients: ## (Intercept) Sepal.Length ## 3.41895 -0.06188  Shortcut for %\u0026gt;% is CTRL + SHIFT + M (or CMD + SHIFT + M for OSX)\n A function that takes a data frame as the first argument, eg. head(), is called a verb\n The entire tidyverse suite operates under the verb function structure, making piping especially convenient\n    Main verbs arrange()  Sort data frame by column(s), lowest to highest  arrange(iris, Petal.Length) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 4.6 3.6 1.0 0.2 setosa ## 2 4.3 3.0 1.1 0.1 setosa ## 3 5.8 4.0 1.2 0.2 setosa ## 4 5.0 3.2 1.2 0.2 setosa ## 5 4.7 3.2 1.3 0.2 setosa ## 6 5.4 3.9 1.3 0.4 setosa ## 7 5.5 3.5 1.3 0.2 setosa ## 8 4.4 3.0 1.3 0.2 setosa ## 9 5.0 3.5 1.3 0.3 setosa ## 10 4.5 2.3 1.3 0.3 setosa ## 11 4.4 3.2 1.3 0.2 setosa ## 12 5.1 3.5 1.4 0.2 setosa ## 13 4.9 3.0 1.4 0.2 setosa ## 14 5.0 3.6 1.4 0.2 setosa ## 15 4.6 3.4 1.4 0.3 setosa  If you specify a variable of class factor or character, you will rearrange the rows to alphabetical order\n Use desc() if you want the opposite order\n  arrange(iris, desc(Species), # sort z to a since species is a factor Sepal.Width) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 6.0 2.2 5.0 1.5 virginica ## 2 4.9 2.5 4.5 1.7 virginica ## 3 6.7 2.5 5.8 1.8 virginica ## 4 5.7 2.5 5.0 2.0 virginica ## 5 6.3 2.5 5.0 1.9 virginica ## 6 7.7 2.6 6.9 2.3 virginica ## 7 6.1 2.6 5.6 1.4 virginica ## 8 5.8 2.7 5.1 1.9 virginica ## 9 6.4 2.7 5.3 1.9 virginica ## 10 6.3 2.7 4.9 1.8 virginica ## 11 5.8 2.7 5.1 1.9 virginica ## 12 5.8 2.8 5.1 2.4 virginica ## 13 5.6 2.8 4.9 2.0 virginica ## 14 7.7 2.8 6.7 2.0 virginica ## 15 6.2 2.8 4.8 1.8 virginica  mutate()  Add a new variable (while preserving all existing variables)  mutate(iris, logSepLength = log(Sepal.Length)) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species logSepLength ## 1 5.1 3.5 1.4 0.2 setosa 1.629241 ## 2 4.9 3.0 1.4 0.2 setosa 1.589235 ## 3 4.7 3.2 1.3 0.2 setosa 1.547563 ## 4 4.6 3.1 1.5 0.2 setosa 1.526056 ## 5 5.0 3.6 1.4 0.2 setosa 1.609438 ## 6 5.4 3.9 1.7 0.4 setosa 1.686399 ## 7 4.6 3.4 1.4 0.3 setosa 1.526056 ## 8 5.0 3.4 1.5 0.2 setosa 1.609438 ## 9 4.4 2.9 1.4 0.2 setosa 1.481605 ## 10 4.9 3.1 1.5 0.1 setosa 1.589235 ## 11 5.4 3.7 1.5 0.2 setosa 1.686399 ## 12 4.8 3.4 1.6 0.2 setosa 1.568616 ## 13 4.8 3.0 1.4 0.1 setosa 1.568616 ## 14 4.3 3.0 1.1 0.1 setosa 1.458615 ## 15 5.8 4.0 1.2 0.2 setosa 1.757858  There’s also transmute() which deletes the old column(s) you use to make the new column  iris %\u0026gt;% transmute(Length_diff = Sepal.Length - Petal.Length, Width_diff = Sepal.Width - Petal.Width) %\u0026gt;% head(n=15) ## Length_diff Width_diff ## 1 3.7 3.3 ## 2 3.5 2.8 ## 3 3.4 3.0 ## 4 3.1 2.9 ## 5 3.6 3.4 ## 6 3.7 3.5 ## 7 3.2 3.1 ## 8 3.5 3.2 ## 9 3.0 2.7 ## 10 3.4 3.0 ## 11 3.9 3.5 ## 12 3.2 3.2 ## 13 3.4 2.9 ## 14 3.2 2.9 ## 15 4.6 3.8  filter()  Return rows matching specified conditions\n Use with \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;=, |, !, %in%, ==, and !=. Separating conditions by , represents the \u0026amp; argument.\n  iris %\u0026gt;% filter(Sepal.Length \u0026gt;= 2) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 12 4.8 3.4 1.6 0.2 setosa ## 13 4.8 3.0 1.4 0.1 setosa ## 14 4.3 3.0 1.1 0.1 setosa ## 15 5.8 4.0 1.2 0.2 setosa iris %\u0026gt;% filter(Petal.Length \u0026gt;= mean(Petal.Length)) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 7.0 3.2 4.7 1.4 versicolor ## 2 6.4 3.2 4.5 1.5 versicolor ## 3 6.9 3.1 4.9 1.5 versicolor ## 4 5.5 2.3 4.0 1.3 versicolor ## 5 6.5 2.8 4.6 1.5 versicolor ## 6 5.7 2.8 4.5 1.3 versicolor ## 7 6.3 3.3 4.7 1.6 versicolor ## 8 6.6 2.9 4.6 1.3 versicolor ## 9 5.2 2.7 3.9 1.4 versicolor ## 10 5.9 3.0 4.2 1.5 versicolor ## 11 6.0 2.2 4.0 1.0 versicolor ## 12 6.1 2.9 4.7 1.4 versicolor ## 13 6.7 3.1 4.4 1.4 versicolor ## 14 5.6 3.0 4.5 1.5 versicolor ## 15 5.8 2.7 4.1 1.0 versicolor iris %\u0026gt;% filter(Species != \u0026quot;versicolor\u0026quot;) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 12 4.8 3.4 1.6 0.2 setosa ## 13 4.8 3.0 1.4 0.1 setosa ## 14 4.3 3.0 1.1 0.1 setosa ## 15 5.8 4.0 1.2 0.2 setosa iris %\u0026gt;% filter(Species %in% c(\u0026quot;versicolor\u0026quot;, \u0026quot;setosa\u0026quot;)) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 12 4.8 3.4 1.6 0.2 setosa ## 13 4.8 3.0 1.4 0.1 setosa ## 14 4.3 3.0 1.1 0.1 setosa ## 15 5.8 4.0 1.2 0.2 setosa  select()  Keep only specified variables  select(iris, Sepal.Length, Sepal.Width) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width ## 1 5.1 3.5 ## 2 4.9 3.0 ## 3 4.7 3.2 ## 4 4.6 3.1 ## 5 5.0 3.6 ## 6 5.4 3.9 ## 7 4.6 3.4 ## 8 5.0 3.4 ## 9 4.4 2.9 ## 10 4.9 3.1 ## 11 5.4 3.7 ## 12 4.8 3.4 ## 13 4.8 3.0 ## 14 4.3 3.0 ## 15 5.8 4.0  Specify variables to exclude with -  select(iris, -Species) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3.0 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5.0 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5.0 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## 11 5.4 3.7 1.5 0.2 ## 12 4.8 3.4 1.6 0.2 ## 13 4.8 3.0 1.4 0.1 ## 14 4.3 3.0 1.1 0.1 ## 15 5.8 4.0 1.2 0.2  Select a range of variables with :  select(iris, Sepal.Length:Petal.Length) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length ## 1 5.1 3.5 1.4 ## 2 4.9 3.0 1.4 ## 3 4.7 3.2 1.3 ## 4 4.6 3.1 1.5 ## 5 5.0 3.6 1.4 ## 6 5.4 3.9 1.7 ## 7 4.6 3.4 1.4 ## 8 5.0 3.4 1.5 ## 9 4.4 2.9 1.4 ## 10 4.9 3.1 1.5 ## 11 5.4 3.7 1.5 ## 12 4.8 3.4 1.6 ## 13 4.8 3.0 1.4 ## 14 4.3 3.0 1.1 ## 15 5.8 4.0 1.2  If you select just one column, you will still get a dataframe. If you need a vector, use pull()  pull(iris, Sepal.Length) %\u0026gt;% head(n=15) ## [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8  summarise()  Condenses data down to one value per group  summarise(iris, mean(Petal.Length)) %\u0026gt;% head(n=15) ## mean(Petal.Length) ## 1 3.758 summarise(iris, sd_pl = sd(Petal.Length), var_pl = sd(Petal.Length)^2) %\u0026gt;% head(n=15) ## sd_pl var_pl ## 1 1.765298 3.116278  group_by()  Invisibly groups data by specified column(s)\n Use with other verbs to get grouped information\n  iris %\u0026gt;% group_by(Species) %\u0026gt;% head(n=15) ## # A tibble: 15 x 5 ## # Groups: Species [1] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 12 4.8 3.4 1.6 0.2 setosa ## 13 4.8 3 1.4 0.1 setosa ## 14 4.3 3 1.1 0.1 setosa ## 15 5.8 4 1.2 0.2 setosa iris %\u0026gt;% group_by(Species) %\u0026gt;% summarise(mean(Petal.Length), sd(Petal.Length)) %\u0026gt;% head(n=15) ## # A tibble: 3 x 3 ## Species `mean(Petal.Length)` `sd(Petal.Length)` ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 setosa 1.46 0.174 ## 2 versicolor 4.26 0.470 ## 3 virginica 5.55 0.552  Data will remain grouped until you use ungroup()   rename()  Give your columns new names. Syntax is newColumn = oldColumn.  iris %\u0026gt;% rename(sep_len = Sepal.Length) %\u0026gt;% head(n=15) ## sep_len Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 12 4.8 3.4 1.6 0.2 setosa ## 13 4.8 3.0 1.4 0.1 setosa ## 14 4.3 3.0 1.1 0.1 setosa ## 15 5.8 4.0 1.2 0.2 setosa   Helper functions everything()  Move columns to the front of your data  select(iris, Species, everything()) %\u0026gt;% head(n=15) ## Species Sepal.Length Sepal.Width Petal.Length Petal.Width ## 1 setosa 5.1 3.5 1.4 0.2 ## 2 setosa 4.9 3.0 1.4 0.2 ## 3 setosa 4.7 3.2 1.3 0.2 ## 4 setosa 4.6 3.1 1.5 0.2 ## 5 setosa 5.0 3.6 1.4 0.2 ## 6 setosa 5.4 3.9 1.7 0.4 ## 7 setosa 4.6 3.4 1.4 0.3 ## 8 setosa 5.0 3.4 1.5 0.2 ## 9 setosa 4.4 2.9 1.4 0.2 ## 10 setosa 4.9 3.1 1.5 0.1 ## 11 setosa 5.4 3.7 1.5 0.2 ## 12 setosa 4.8 3.4 1.6 0.2 ## 13 setosa 4.8 3.0 1.4 0.1 ## 14 setosa 4.3 3.0 1.1 0.1 ## 15 setosa 5.8 4.0 1.2 0.2  starts_with() select(iris, starts_with(\u0026quot;Petal\u0026quot;)) %\u0026gt;% head(n=15) ## Petal.Length Petal.Width ## 1 1.4 0.2 ## 2 1.4 0.2 ## 3 1.3 0.2 ## 4 1.5 0.2 ## 5 1.4 0.2 ## 6 1.7 0.4 ## 7 1.4 0.3 ## 8 1.5 0.2 ## 9 1.4 0.2 ## 10 1.5 0.1 ## 11 1.5 0.2 ## 12 1.6 0.2 ## 13 1.4 0.1 ## 14 1.1 0.1 ## 15 1.2 0.2  ends_with() select(iris, ends_with(\u0026quot;Length\u0026quot;)) %\u0026gt;% head(n=15) ## Sepal.Length Petal.Length ## 1 5.1 1.4 ## 2 4.9 1.4 ## 3 4.7 1.3 ## 4 4.6 1.5 ## 5 5.0 1.4 ## 6 5.4 1.7 ## 7 4.6 1.4 ## 8 5.0 1.5 ## 9 4.4 1.4 ## 10 4.9 1.5 ## 11 5.4 1.5 ## 12 4.8 1.6 ## 13 4.8 1.4 ## 14 4.3 1.1 ## 15 5.8 1.2  contains()  Searches column names for a specified string  select(iris, contains(\u0026quot;Wid\u0026quot;)) %\u0026gt;% head(n=15) ## Sepal.Width Petal.Width ## 1 3.5 0.2 ## 2 3.0 0.2 ## 3 3.2 0.2 ## 4 3.1 0.2 ## 5 3.6 0.2 ## 6 3.9 0.4 ## 7 3.4 0.3 ## 8 3.4 0.2 ## 9 2.9 0.2 ## 10 3.1 0.1 ## 11 3.7 0.2 ## 12 3.4 0.2 ## 13 3.0 0.1 ## 14 3.0 0.1 ## 15 4.0 0.2  matches()  Searches column names for a specified regular expression  select(iris, matches(\u0026quot;wid|spec\u0026quot;)) %\u0026gt;% head(n=15) ## Sepal.Width Petal.Width Species ## 1 3.5 0.2 setosa ## 2 3.0 0.2 setosa ## 3 3.2 0.2 setosa ## 4 3.1 0.2 setosa ## 5 3.6 0.2 setosa ## 6 3.9 0.4 setosa ## 7 3.4 0.3 setosa ## 8 3.4 0.2 setosa ## 9 2.9 0.2 setosa ## 10 3.1 0.1 setosa ## 11 3.7 0.2 setosa ## 12 3.4 0.2 setosa ## 13 3.0 0.1 setosa ## 14 3.0 0.1 setosa ## 15 4.0 0.2 setosa For more info on regex see here\n row_number()  Specify which row number you want for your verb  iris %\u0026gt;% group_by(Species) %\u0026gt;% filter(row_number() == 1) %\u0026gt;% head(n=15) ## # A tibble: 3 x 5 ## # Groups: Species [3] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 7 3.2 4.7 1.4 versicolor ## 3 6.3 3.3 6 2.5 virginica  n()  References the number of rows in your data frame (or for each group in a 'grouped_df')  iris %\u0026gt;% group_by(Species) %\u0026gt;% filter(row_number() == n()) %\u0026gt;% head(n=15) ## # A tibble: 3 x 5 ## # Groups: Species [3] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 5 3.3 1.4 0.2 setosa ## 2 5.7 2.8 4.1 1.3 versicolor ## 3 5.9 3 5.1 1.8 virginica   Fancy verbs  Scoped verbs take the additional arguments .predicate, .funs, and .vars\n They end in _at(), _if() and _all()\n Signify what function (.funs) should be applied too all variables, only at certain variables (.vars), or only if variables meet a certain condition (.predicate)\n ie. mutate_at(), mutate_if(), mutate_all(), summarise_if(), summarise_at(), summarise_all(), select_if(), select_at(), rename_if(), filter_all(), arrange_all(), group_by_at() …the list goes on!\n A few examples (we will see more later)\n  iris %\u0026gt;% select_if(.predicate = is.numeric) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3.0 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5.0 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5.0 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## 11 5.4 3.7 1.5 0.2 ## 12 4.8 3.4 1.6 0.2 ## 13 4.8 3.0 1.4 0.1 ## 14 4.3 3.0 1.1 0.1 ## 15 5.8 4.0 1.2 0.2 iris %\u0026gt;% select_if(.predicate = is.numeric, .funs=funs(paste0(\u0026quot;num_\u0026quot;,.))) %\u0026gt;% head(n=15) # can also be used to rename ## num_Sepal.Length num_Sepal.Width num_Petal.Length num_Petal.Width ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3.0 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5.0 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5.0 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## 11 5.4 3.7 1.5 0.2 ## 12 4.8 3.4 1.6 0.2 ## 13 4.8 3.0 1.4 0.1 ## 14 4.3 3.0 1.1 0.1 ## 15 5.8 4.0 1.2 0.2 iris %\u0026gt;% summarise_if(.predicate = is.numeric, .funs = funs(mean(., na.rm=T))) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 1 5.843333 3.057333 3.758 1.199333 iris %\u0026gt;% mutate_at(.vars = vars(c(\u0026quot;Sepal.Length\u0026quot;,\u0026quot;Petal.Length\u0026quot;)), .funs = funs(scale)) %\u0026gt;% head(n=15) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 -0.89767388 3.5 -1.335752 0.2 setosa ## 2 -1.13920048 3.0 -1.335752 0.2 setosa ## 3 -1.38072709 3.2 -1.392399 0.2 setosa ## 4 -1.50149039 3.1 -1.279104 0.2 setosa ## 5 -1.01843718 3.6 -1.335752 0.2 setosa ## 6 -0.53538397 3.9 -1.165809 0.4 setosa ## 7 -1.50149039 3.4 -1.335752 0.3 setosa ## 8 -1.01843718 3.4 -1.279104 0.2 setosa ## 9 -1.74301699 2.9 -1.335752 0.2 setosa ## 10 -1.13920048 3.1 -1.279104 0.1 setosa ## 11 -0.53538397 3.7 -1.279104 0.2 setosa ## 12 -1.25996379 3.4 -1.222456 0.2 setosa ## 13 -1.25996379 3.0 -1.335752 0.1 setosa ## 14 -1.86378030 3.0 -1.505695 0.1 setosa ## 15 -0.05233076 4.0 -1.449047 0.2 setosa # z scores by Species for all numeric variables iris %\u0026gt;% group_by(Species) %\u0026gt;% mutate_if(.predicate = is.numeric, .funs = funs(scale)) %\u0026gt;% head(n=15) ## # A tibble: 15 x 5 ## # Groups: Species [1] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 0.267 0.190 -0.357 -0.436 setosa ## 2 -0.301 -1.13 -0.357 -0.436 setosa ## 3 -0.868 -0.601 -0.933 -0.436 setosa ## 4 -1.15 -0.865 0.219 -0.436 setosa ## 5 -0.0170 0.454 -0.357 -0.436 setosa ## 6 1.12 1.25 1.37 1.46 setosa ## 7 -1.15 -0.0739 -0.357 0.512 setosa ## 8 -0.0170 -0.0739 0.219 -0.436 setosa ## 9 -1.72 -1.39 -0.357 -0.436 setosa ## 10 -0.301 -0.865 0.219 -1.39 setosa ## 11 1.12 0.718 0.219 -0.436 setosa ## 12 -0.584 -0.0739 0.795 -0.436 setosa ## 13 -0.584 -1.13 -0.357 -1.39 setosa ## 14 -2.00 -1.13 -2.08 -1.39 setosa ## 15 2.25 1.51 -1.51 -0.436 setosa  I have never used any of the group_by_*() but I imagine they’re useful when you have a large selection of identifiers/grouping variables that you can call easily with a predicate (for example, is.factor). They can also be used with a .funs argument as a shortcut to group_by() %\u0026gt;% mutate().   Miscellaneous verbs lag()  Makes a new column with the value of one row previously   lead()  Makes a new column with the value of one row ahead  x \u0026lt;- runif(5) cbind(ahead = lead(x), x, behind = lag(x)) ## ahead x behind ## [1,] 0.47072787 0.78080563 NA ## [2,] 0.64402818 0.47072787 0.7808056 ## [3,] 0.32345814 0.64402818 0.4707279 ## [4,] 0.08515902 0.32345814 0.6440282 ## [5,] NA 0.08515902 0.3234581  Can choose a time column to order your new values by with the argument 'order_by'   Lag and lead are very useful for longitudinal models   complete() incomplete_df \u0026lt;- data.frame(day = c(1,3,7,9), dose = c(0, 25, 40, 30)) %\u0026gt;% head(n=15) incomplete_df ## day dose ## 1 1 0 ## 2 3 25 ## 3 7 40 ## 4 9 30 complete(incomplete_df, day = full_seq(1:max(day), 1)) %\u0026gt;% head(n=15) ## # A tibble: 9 x 2 ## day dose ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 0 ## 2 2 NA ## 3 3 25 ## 4 4 NA ## 5 5 NA ## 6 6 NA ## 7 7 40 ## 8 8 NA ## 9 9 30  fill()  Fill in missing values with values before or after  incomplete_df %\u0026gt;% complete(day = full_seq(1:max(day), 1)) %\u0026gt;% fill(dose, .direction = \u0026quot;down\u0026quot;) %\u0026gt;% head(n=15) ## # A tibble: 9 x 2 ## day dose ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 0 ## 2 2 0 ## 3 3 25 ## 4 4 25 ## 5 5 25 ## 6 6 25 ## 7 7 40 ## 8 8 40 ## 9 9 30  drop_na() incomplete_df %\u0026gt;% complete(day = full_seq(1:max(day), 1)) %\u0026gt;% drop_na() %\u0026gt;% head(n=15) # when you have more variables, specify which columns you care about dropping NAs from ## # A tibble: 4 x 2 ## day dose ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 0 ## 2 3 25 ## 3 7 40 ## 4 9 30  sample_frac()  Randomly sample a specified fraction of rows of a data frame  mydat \u0026lt;- data.frame(id = sample(1:100, 20), meas = rnorm(20)) mydat ## id meas ## 1 57 2.288186793 ## 2 100 -1.602300385 ## 3 46 0.609128605 ## 4 85 -0.481366290 ## 5 71 -0.333337018 ## 6 99 0.551787362 ## 7 5 -0.042839936 ## 8 75 -0.803681418 ## 9 67 0.904749782 ## 10 23 0.333527940 ## 11 77 0.040703715 ## 12 33 0.002205167 ## 13 37 0.943927491 ## 14 41 1.027059802 ## 15 64 1.005199118 ## 16 62 0.591302764 ## 17 3 1.262050643 ## 18 7 -0.644000308 ## 19 97 -0.768234573 ## 20 45 0.698145334 mydat %\u0026gt;% sample_frac(size = .5) ## id meas ## 1 71 -0.3333370 ## 2 3 1.2620506 ## 3 75 -0.8036814 ## 4 85 -0.4813663 ## 5 45 0.6981453 ## 6 64 1.0051991 ## 7 100 -1.6023004 ## 8 62 0.5913028 ## 9 37 0.9439275 ## 10 41 1.0270598 mydat %\u0026gt;% sample_frac(size= .5, replace = T) # you can also add sampling weights ## id meas ## 1 62 0.591302764 ## 2 75 -0.803681418 ## 3 33 0.002205167 ## 4 97 -0.768234573 ## 5 23 0.333527940 ## 6 23 0.333527940 ## 7 67 0.904749782 ## 8 62 0.591302764 ## 9 85 -0.481366290 ## 10 75 -0.803681418  sample_n()  Randomly sample a specified number of rows of a data frame  mydat %\u0026gt;% sample_n(3) ## id meas ## 1 62 0.5913028 ## 2 37 0.9439275 ## 3 41 1.0270598   Joining functions x \u0026lt;- data.frame(id = c(\u0026quot;A\u0026quot;,\u0026quot;B\u0026quot;,\u0026quot;C\u0026quot;), val = 1:3) y \u0026lt;- data.frame(id = c(\u0026quot;A\u0026quot;,\u0026quot;B\u0026quot;,\u0026quot;D\u0026quot;), val = c(\u0026quot;T\u0026quot;,\u0026quot;F\u0026quot;,\u0026quot;T\u0026quot;)) x ## id val ## 1 A 1 ## 2 B 2 ## 3 C 3 y ## id val ## 1 A T ## 2 B F ## 3 D T  “Mutating” joins combine variables from the left and right hand sides ie. full_join(), inner_join(), right_join(), and left_join()  full_join()  Return all rows and columns  full_join(x, y, by = \u0026quot;id\u0026quot;) ## id val.x val.y ## 1 A 1 T ## 2 B 2 F ## 3 C 3 \u0026lt;NA\u0026gt; ## 4 D NA T  inner_join()  Return all rows from x that have a match in y, and all columns from x and y  inner_join(x, y, by = \u0026quot;id\u0026quot;) ## id val.x val.y ## 1 A 1 T ## 2 B 2 F  left_join()  Return all rows from x and all columns from x and y  left_join(x, y, by = \u0026quot;id\u0026quot;) ## id val.x val.y ## 1 A 1 T ## 2 B 2 F ## 3 C 3 \u0026lt;NA\u0026gt;  right_join()  Return all rows from x and all columns from x and y  right_join(x, y, by = \u0026quot;id\u0026quot;) ## id val.x val.y ## 1 A 1 T ## 2 B 2 F ## 3 D NA T  “Filtering” joins keep cases from the left hand side, ie. semi_join() and anti_join()   semi_join()  Return all rows in x that have a match in y, keeping only columns from y  semi_join(x, y, by = \u0026quot;id\u0026quot;) ## id val ## 1 A 1 ## 2 B 2  anti_join()  Return all rows from x where there are not matching values in y, keeping just the columns from x  anti_join(x, y, by = \u0026quot;id\u0026quot;) ## id val ## 1 C 3   Incorporating dplyr into your workflow Frequency Tables library(kableExtra) mtcars %\u0026gt;% group_by(vs, am) %\u0026gt;% summarise(n=n(), freq=n()/nrow(.)) %\u0026gt;% kable(caption=\u0026quot;Frequency Table of vs and am\u0026quot;, format=\u0026quot;html\u0026quot;) %\u0026gt;% kable_styling(c(\u0026quot;condensed\u0026quot;,\u0026quot;responsive\u0026quot;,\u0026quot;striped\u0026quot;,\u0026quot;hover\u0026quot;), full_width = F)  Table 1: Frequency Table of vs and am    vs  am  n  freq      0  0  12  0.37500    0  1  6  0.18750    1  0  7  0.21875    1  1  7  0.21875      compareGroups library(compareGroups) iris %\u0026gt;% mutate(Sepal.Length.Sq = Sepal.Length^2) %\u0026gt;% compareGroups(Species ~ ., data = .) %\u0026gt;% createTable() %\u0026gt;% export2md() %\u0026gt;% kable_styling(c(\u0026quot;condensed\u0026quot;,\u0026quot;responsive\u0026quot;,\u0026quot;striped\u0026quot;,\u0026quot;hover\u0026quot;))  Table 2: Summary descriptives table by groups of `Species’     setosa  versicolor  virginica  p.overall       N=50  N=50  N=50     Sepal.Length  5.01 (0.35)  5.94 (0.52)  6.59 (0.64)  \u0026lt;0.001    Sepal.Width  3.43 (0.38)  2.77 (0.31)  2.97 (0.32)  \u0026lt;0.001    Petal.Length  1.46 (0.17)  4.26 (0.47)  5.55 (0.55)  \u0026lt;0.001    Petal.Width  0.25 (0.11)  1.33 (0.20)  2.03 (0.27)  \u0026lt;0.001    Sepal.Length.Sq  25.2 (3.55)  35.5 (6.16)  43.8 (8.44)  \u0026lt;0.001      ggplotting iris %\u0026gt;% filter(Species != \u0026quot;setosa\u0026quot;) %\u0026gt;% ggplot(aes(Sepal.Length, Petal.Width, col=Species)) + geom_point()  Finding columns of interest  When you have too many column names to look through manually, search for a string or pattern of strings  load(\u0026quot;dplyr_dat.Rdata\u0026quot;) length(names(brain)) ## [1] 1000 select(brain, matches(\u0026quot;pib.*parietal.*\u0026quot;)) %\u0026gt;% names() # regex is not case sensitive ## [1] \u0026quot;PIB.PET_AAL__Parietal_Inf_L\u0026quot; ## [2] \u0026quot;PIB.PET_AAL__Parietal_Inf_R\u0026quot; ## [3] \u0026quot;PIB.PET_AAL__Parietal_Sup_L\u0026quot; ## [4] \u0026quot;PIB.PET_AAL__Parietal_Sup_R\u0026quot; ## [5] \u0026quot;PIB.PET_FS__ctx.lh.inferiorparietal\u0026quot; ## [6] \u0026quot;PIB.PET_FS__ctx.lh.superiorparietal\u0026quot; ## [7] \u0026quot;PIB.PET_FS__ctx.rh.inferiorparietal\u0026quot; ## [8] \u0026quot;PIB.PET_FS__ctx.rh.superiorparietal\u0026quot; % -- % -- % --  Missing data wrangling  Add a column flagging a value as missing and then replace the missing values with the mean of the other values  misdat \u0026lt;- data.frame(x1 = sample(c(1:3, NA), 13, replace=T), x2 = sample(c(-5:-2,NA), 13, replace=T)) misdat ## x1 x2 ## 1 3 -3 ## 2 3 -5 ## 3 3 -2 ## 4 NA NA ## 5 NA -5 ## 6 NA -2 ## 7 1 -3 ## 8 3 NA ## 9 1 -4 ## 10 NA -3 ## 11 NA -4 ## 12 3 -5 ## 13 NA -4 misdat %\u0026gt;% mutate_all(.funs = funs(miss = ifelse(is.na(.), 1, 0))) %\u0026gt;% mutate_all(.funs = funs(replace_na(., mean(., na.rm=T)))) ## x1 x2 x1_miss x2_miss ## 1 3.000000 -3.000000 0 0 ## 2 3.000000 -5.000000 0 0 ## 3 3.000000 -2.000000 0 0 ## 4 2.428571 -3.636364 1 1 ## 5 2.428571 -5.000000 1 0 ## 6 2.428571 -2.000000 1 0 ## 7 1.000000 -3.000000 0 0 ## 8 3.000000 -3.636364 0 1 ## 9 1.000000 -4.000000 0 0 ## 10 2.428571 -3.000000 1 0 ## 11 2.428571 -4.000000 1 0 ## 12 3.000000 -5.000000 0 0 ## 13 2.428571 -4.000000 1 0  Longitudinal data wrangling A  Calculate the time since a patient was first admitted to the hospital  id \u0026lt;- c(1,1,1,2,2,2,2,3) admit \u0026lt;- as.Date(c(\u0026quot;2017-06-22\u0026quot;, \u0026quot;2017-07-13\u0026quot;, \u0026quot;2017-08-29\u0026quot;, \u0026quot;2017-04-01\u0026quot;, \u0026quot;2017-05-02\u0026quot;, \u0026quot;2017-11-14\u0026quot;, \u0026quot;2018-01-14\u0026quot;, \u0026quot;2019-01-01\u0026quot;)) discharge \u0026lt;- as.Date(c(\u0026quot;2017-06-25\u0026quot;, \u0026quot;2017-07-31\u0026quot;, \u0026quot;2017-10-13\u0026quot;, \u0026quot;2017-04-02\u0026quot;, \u0026quot;2017-05-10\u0026quot;, \u0026quot;2017-11-18\u0026quot;, \u0026quot;2018-02-12\u0026quot;, \u0026quot;2019-01-05\u0026quot;)) hosp_dat \u0026lt;- data.frame(id, admit, discharge) hosp_dat ## id admit discharge ## 1 1 2017-06-22 2017-06-25 ## 2 1 2017-07-13 2017-07-31 ## 3 1 2017-08-29 2017-10-13 ## 4 2 2017-04-01 2017-04-02 ## 5 2 2017-05-02 2017-05-10 ## 6 2 2017-11-14 2017-11-18 ## 7 2 2018-01-14 2018-02-12 ## 8 3 2019-01-01 2019-01-05 hosp_dat %\u0026gt;% group_by(id) %\u0026gt;% mutate(days_since_init_admit = discharge - admit[1]) ## # A tibble: 8 x 4 ## # Groups: id [3] ## id admit discharge days_since_init_admit ## \u0026lt;dbl\u0026gt; \u0026lt;date\u0026gt; \u0026lt;date\u0026gt; \u0026lt;drtn\u0026gt; ## 1 1 2017-06-22 2017-06-25 3 days ## 2 1 2017-07-13 2017-07-31 39 days ## 3 1 2017-08-29 2017-10-13 113 days ## 4 2 2017-04-01 2017-04-02 1 days ## 5 2 2017-05-02 2017-05-10 39 days ## 6 2 2017-11-14 2017-11-18 231 days ## 7 2 2018-01-14 2018-02-12 317 days ## 8 3 2019-01-01 2019-01-05 4 days  Longitudinal data wrangling B  Make a row for every patient for every month from the start of follow up to the end of follow up (get equally spaced time intervals)\n Make another column containing the drugs the patient was on previously (for prediction or longitudinal models)\n  load(\u0026quot;meds.Rdata\u0026quot;) meds ## PatientID Months_ImplantToVisit BB_yn ACE_yn ARB_yn ## 1 1 1 0 0 0 ## 2 1 2 0 0 0 ## 3 2 2 0 1 0 ## 4 2 3 0 1 0 ## 5 2 4 0 1 0 ## 6 2 5 0 1 0 ## 7 2 6 1 1 0 ## 8 2 8 1 1 0 ## 9 2 10 1 1 0 ## 10 2 12 1 1 0 ## 11 2 13 1 1 0 ## 12 2 14 1 1 0 ## 13 2 16 1 1 0 ## 14 3 2 0 0 0 ## 15 3 3 0 0 0 meds %\u0026gt;% group_by(PatientID) %\u0026gt;% complete(Months_ImplantToVisit = full_seq(1:max(Months_ImplantToVisit), 1)) %\u0026gt;% fill(ends_with(\u0026quot;_yn\u0026quot;)) %\u0026gt;% fill(ends_with(\u0026quot;_yn\u0026quot;), .direction=\u0026quot;up\u0026quot;) -\u0026gt; meds1 meds1 ## # A tibble: 21 x 5 ## # Groups: PatientID [3] ## PatientID Months_ImplantToVisit BB_yn ACE_yn ARB_yn ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; ## 1 1 1 0 0 0 ## 2 1 2 0 0 0 ## 3 2 1 0 1 0 ## 4 2 2 0 1 0 ## 5 2 3 0 1 0 ## 6 2 4 0 1 0 ## 7 2 5 0 1 0 ## 8 2 6 1 1 0 ## 9 2 7 1 1 0 ## 10 2 8 1 1 0 ## # … with 11 more rows meds1 %\u0026gt;% mutate_at(.vars = vars(ends_with(\u0026quot;_yn\u0026quot;)), .funs = funs(prev = lag(., order_by = Months_ImplantToVisit))) %\u0026gt;% fill(ends_with(\u0026quot;_prev\u0026quot;), .direction=\u0026quot;up\u0026quot;) %\u0026gt;% head(n=15) ## # A tibble: 15 x 8 ## # Groups: PatientID [2] ## PatientID Months_ImplantT… BB_yn ACE_yn ARB_yn BB_yn_prev ACE_yn_prev ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; ## 1 1 1 0 0 0 0 0 ## 2 1 2 0 0 0 0 0 ## 3 2 1 0 1 0 0 1 ## 4 2 2 0 1 0 0 1 ## 5 2 3 0 1 0 0 1 ## 6 2 4 0 1 0 0 1 ## 7 2 5 0 1 0 0 1 ## 8 2 6 1 1 0 0 1 ## 9 2 7 1 1 0 1 1 ## 10 2 8 1 1 0 1 1 ## 11 2 9 1 1 0 1 1 ## 12 2 10 1 1 0 1 1 ## 13 2 11 1 1 0 1 1 ## 14 2 12 1 1 0 1 1 ## 15 2 13 1 1 0 1 1 ## # … with 1 more variable: ARB_yn_prev \u0026lt;fct\u0026gt;  Survival data wrangling  Map four columns “days to…outcome” to a composite endpoint for a survival model\n Record when the event occurred as Days.to.first.event and which event it was in FE.status\n  dems %\u0026gt;% select(Days.to.lastFU, Days.to.death, Days.to.stroke, Days.to.GIB, Days.to.PT) %\u0026gt;% # which.min cannot handle NA, so we\u0026#39;ll make NA\u0026#39;s infinity for now replace(is.na(.), Inf) %\u0026gt;% # to allow which.min to search along rows (dplyr naturally looks down columns) rowwise() %\u0026gt;% mutate( FUorFEtime = pmin(Days.to.lastFU, Days.to.death, Days.to.stroke, Days.to.GIB, Days.to.PT, na.rm = T), # numbers correspond to order of the Days* columns FUorFEstatus = which.min(c(Days.to.lastFU, Days.to.death, Days.to.stroke, Days.to.GIB, Days.to.PT)), # condensed variable for survival model, 1 if any event Event_yn = ifelse(FUorFEstatus == 1, 0, 1)) -\u0026gt; dems_int dems_int # look at the intermediate output ## Source: local data frame [265 x 8] ## Groups: \u0026lt;by row\u0026gt; ## ## # A tibble: 265 x 8 ## Days.to.lastFU Days.to.death Days.to.stroke Days.to.GIB Days.to.PT ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 98 98 94 Inf Inf ## 2 163 Inf Inf Inf 141 ## 3 185 Inf Inf Inf Inf ## 4 139 Inf Inf Inf Inf ## 5 196 Inf Inf 78 Inf ## 6 161 Inf Inf Inf Inf ## 7 210 Inf 185 Inf Inf ## 8 233 Inf Inf Inf Inf ## 9 239 Inf Inf Inf Inf ## 10 243 Inf Inf Inf Inf ## # … with 255 more rows, and 3 more variables: FUorFEtime \u0026lt;dbl\u0026gt;, ## # FUorFEstatus \u0026lt;int\u0026gt;, Event_yn \u0026lt;dbl\u0026gt; dems_int %\u0026gt;% # column names correspond to the order of the columns, rename mutate(FUorFEstatus = case_when(FUorFEstatus == 1 ~ \u0026quot;censored\u0026quot;, FUorFEstatus == 2 ~ \u0026quot;death\u0026quot;, FUorFEstatus == 3 ~ \u0026quot;stroke\u0026quot;, FUorFEstatus == 4 ~ \u0026quot;gib\u0026quot;, FUorFEstatus == 5 ~ \u0026quot;pt\u0026quot;, TRUE ~ \u0026quot;error\u0026quot;)) %\u0026gt;% # not case sensitive select(contains(\u0026quot;fe\u0026quot;), Event_yn) %\u0026gt;% # allow for joining with no duplicate cols rownames_to_column() %\u0026gt;% full_join(dems %\u0026gt;% rownames_to_column()) %\u0026gt;% select(-rowname) -\u0026gt; dems_clean # check to make sure everything worked dems_clean %\u0026gt;% filter(FUorFEstatus == \u0026quot;error\u0026quot;) ## Source: local data frame [0 x 55] ## Groups: \u0026lt;by row\u0026gt; ## ## # A tibble: 0 x 55 ## # … with 55 variables: FUorFEtime \u0026lt;dbl\u0026gt;, FUorFEstatus \u0026lt;chr\u0026gt;, ## # Event_yn \u0026lt;dbl\u0026gt;, PatientID \u0026lt;int\u0026gt;, Year.of.Implant \u0026lt;int\u0026gt;, Outcome \u0026lt;int\u0026gt;, ## # Days.to.lastFU \u0026lt;int\u0026gt;, Stroke \u0026lt;int\u0026gt;, Days.to.stroke \u0026lt;int\u0026gt;, ## # TypeStroke \u0026lt;int\u0026gt;, Stroke_IA \u0026lt;int\u0026gt;, Days.to.IA.stroke \u0026lt;int\u0026gt;, ## # TypeStroke_IA \u0026lt;int\u0026gt;, PT \u0026lt;int\u0026gt;, Days.to.PT \u0026lt;int\u0026gt;, GIB \u0026lt;int\u0026gt;, ## # Days.to.GIB \u0026lt;int\u0026gt;, GIB_IA \u0026lt;int\u0026gt;, Days.to.GIB_IA \u0026lt;int\u0026gt;, ## # Age.at.implant \u0026lt;int\u0026gt;, Sex \u0026lt;fct\u0026gt;, Race \u0026lt;int\u0026gt;, Caucasian \u0026lt;int\u0026gt;, ## # AfibFlut \u0026lt;fct\u0026gt;, Smoking_Hx \u0026lt;fct\u0026gt;, DM \u0026lt;fct\u0026gt;, Ischemic \u0026lt;int\u0026gt;, ## # HTN_Hx \u0026lt;fct\u0026gt;, Stroke_Hx \u0026lt;fct\u0026gt;, Pulmonary_Hx \u0026lt;fct\u0026gt;, ICD \u0026lt;fct\u0026gt;, ## # IMCS \u0026lt;int\u0026gt;, DT \u0026lt;int\u0026gt;, Hb_pre \u0026lt;dbl\u0026gt;, PLT_pre \u0026lt;int\u0026gt;, INR_dx \u0026lt;dbl\u0026gt;, ## # Creat_dx \u0026lt;dbl\u0026gt;, Height \u0026lt;dbl\u0026gt;, Weight \u0026lt;dbl\u0026gt;, BMI \u0026lt;dbl\u0026gt;, Speed \u0026lt;int\u0026gt;, ## # PI \u0026lt;dbl\u0026gt;, Flow \u0026lt;dbl\u0026gt;, RVAD \u0026lt;fct\u0026gt;, IABP \u0026lt;fct\u0026gt;, ## # Days.to.first.outpt.visit \u0026lt;int\u0026gt;, Days.to.IA.discharge \u0026lt;int\u0026gt;, EF \u0026lt;fct\u0026gt;, ## # LVEDD \u0026lt;fct\u0026gt;, RV_Dysf \u0026lt;fct\u0026gt;, LDH_Dx \u0026lt;int\u0026gt;, eGFR \u0026lt;dbl\u0026gt;, AvgMAP \u0026lt;lgl\u0026gt;, ## # Death \u0026lt;int\u0026gt;, Days.to.death \u0026lt;int\u0026gt; dems_clean %\u0026gt;% head(n=15) ## Source: local data frame [15 x 55] ## Groups: \u0026lt;by row\u0026gt; ## ## # A tibble: 15 x 55 ## FUorFEtime FUorFEstatus Event_yn PatientID Year.of.Implant Outcome ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 94 stroke 1 1 2016 2 ## 2 141 pt 1 2 2016 7 ## 3 185 censored 0 3 2016 7 ## 4 139 censored 0 4 2016 6 ## 5 78 gib 1 5 2016 7 ## 6 161 censored 0 6 2016 1 ## 7 185 stroke 1 7 2016 7 ## 8 233 censored 0 8 2016 7 ## 9 239 censored 0 9 2016 7 ## 10 243 censored 0 10 2016 7 ## 11 248 censored 0 11 2016 7 ## 12 51 pt 1 12 2016 1 ## 13 37 gib 1 13 2016 7 ## 14 261 censored 0 14 2016 7 ## 15 265 censored 0 15 2016 7 ## # … with 49 more variables: Days.to.lastFU \u0026lt;int\u0026gt;, Stroke \u0026lt;int\u0026gt;, ## # Days.to.stroke \u0026lt;int\u0026gt;, TypeStroke \u0026lt;int\u0026gt;, Stroke_IA \u0026lt;int\u0026gt;, ## # Days.to.IA.stroke \u0026lt;int\u0026gt;, TypeStroke_IA \u0026lt;int\u0026gt;, PT \u0026lt;int\u0026gt;, ## # Days.to.PT \u0026lt;int\u0026gt;, GIB \u0026lt;int\u0026gt;, Days.to.GIB \u0026lt;int\u0026gt;, GIB_IA \u0026lt;int\u0026gt;, ## # Days.to.GIB_IA \u0026lt;int\u0026gt;, Age.at.implant \u0026lt;int\u0026gt;, Sex \u0026lt;fct\u0026gt;, Race \u0026lt;int\u0026gt;, ## # Caucasian \u0026lt;int\u0026gt;, AfibFlut \u0026lt;fct\u0026gt;, Smoking_Hx \u0026lt;fct\u0026gt;, DM \u0026lt;fct\u0026gt;, ## # Ischemic \u0026lt;int\u0026gt;, HTN_Hx \u0026lt;fct\u0026gt;, Stroke_Hx \u0026lt;fct\u0026gt;, Pulmonary_Hx \u0026lt;fct\u0026gt;, ## # ICD \u0026lt;fct\u0026gt;, IMCS \u0026lt;int\u0026gt;, DT \u0026lt;int\u0026gt;, Hb_pre \u0026lt;dbl\u0026gt;, PLT_pre \u0026lt;int\u0026gt;, ## # INR_dx \u0026lt;dbl\u0026gt;, Creat_dx \u0026lt;dbl\u0026gt;, Height \u0026lt;dbl\u0026gt;, Weight \u0026lt;dbl\u0026gt;, BMI \u0026lt;dbl\u0026gt;, ## # Speed \u0026lt;int\u0026gt;, PI \u0026lt;dbl\u0026gt;, Flow \u0026lt;dbl\u0026gt;, RVAD \u0026lt;fct\u0026gt;, IABP \u0026lt;fct\u0026gt;, ## # Days.to.first.outpt.visit \u0026lt;int\u0026gt;, Days.to.IA.discharge \u0026lt;int\u0026gt;, EF \u0026lt;fct\u0026gt;, ## # LVEDD \u0026lt;fct\u0026gt;, RV_Dysf \u0026lt;fct\u0026gt;, LDH_Dx \u0026lt;int\u0026gt;, eGFR \u0026lt;dbl\u0026gt;, AvgMAP \u0026lt;lgl\u0026gt;, ## # Death \u0026lt;int\u0026gt;, Days.to.death \u0026lt;int\u0026gt;  Making functions  Problem: dplyr doesn’t know what to do with quotes around the variable name, but you can’t put the column name into a function without quotes because R will try to find it as an object in your environment…\n Solution: relying on the rlang package (sym, !!, !!!, etc)  A good tutorial: http://jonthegeek.com/2018/06/04/writing-custom-tidyverse-functions/   irisSummary \u0026lt;- function(group){ iris %\u0026gt;% group_by(!!sym(group)) %\u0026gt;% summarise(mean(Sepal.Length), sd(Sepal.Length)) } irisSummary(group = \u0026quot;Species\u0026quot;) ## # A tibble: 3 x 3 ## Species `mean(Sepal.Length)` `sd(Sepal.Length)` ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 setosa 5.01 0.352 ## 2 versicolor 5.94 0.516 ## 3 virginica 6.59 0.636 irisScatPlot \u0026lt;- function(x, y){ iris %\u0026gt;% ggplot(aes_string(x, y, col=\u0026quot;Species\u0026quot;)) + geom_point() -\u0026gt; p return(p) } irisScatPlot(x=\u0026quot;Sepal.Length\u0026quot;,y=\u0026quot;Petal.Length\u0026quot;)   ","date":1551838394,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551838394,"objectID":"1f04305f4b66b881b2e897844dc52e16","permalink":"/tutorial/dplyr/data-wrangling/","publishdate":"2019-03-05T21:13:14-05:00","relpermalink":"/tutorial/dplyr/data-wrangling/","section":"tutorial","summary":"A Presentation for Weill Cornell Medicine’s Biostatistics Computing Club Image courtesy of Allison Horst’s Twitter: @allison_horst\n Introduction Why dplyr?  Powerful but efficient\n Consistent syntax\n Fast\n  Function chaining\n Works well with entire tidyverse suite   Efficiency*\n Simple syntax\n Function chaining\n Ability to analyze external databases\n Works well with other packages in tidyverse suite ggplot2 tidyr stringr forcats purrr   *if you start dealing with data sets with \u0026gt; 1 million rows, data.","tags":["dplyr","R","rstats"],"title":"Data Wrangling with dplyr","type":"tutorial"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":null,"content":"","date":1519898400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519898400,"objectID":"fd67e3d6cb6945af135ce88aa88ba0a6","permalink":"/talk/shanghai/","publishdate":"2018-03-01T00:00:00Z","relpermalink":"/talk/shanghai/","section":"talk","summary":"An overview of the US air pollution and renal dysfunction databases","tags":[],"title":"Air Pollution and Renal Failure Incidence","type":"talk"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":null,"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":null,"title":"Internal Project","type":"project"},{"authors":["Katherine Hoffman","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"An example journal article","type":"publication"},{"authors":["Katherine Hoffman","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"An example conference paper","type":"publication"}]